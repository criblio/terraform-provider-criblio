// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
	"github.com/criblio/terraform-provider-criblio/internal/sdk/internal/utils"
)

type OutputCloudflareR2Type string

const (
	OutputCloudflareR2TypeCloudflareR2 OutputCloudflareR2Type = "cloudflare_r2"
)

func (e OutputCloudflareR2Type) ToPointer() *OutputCloudflareR2Type {
	return &e
}
func (e *OutputCloudflareR2Type) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cloudflare_r2":
		*e = OutputCloudflareR2Type(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudflareR2Type: %v", v)
	}
}

// OutputCloudflareR2AuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type OutputCloudflareR2AuthenticationMethod string

const (
	OutputCloudflareR2AuthenticationMethodAuto   OutputCloudflareR2AuthenticationMethod = "auto"
	OutputCloudflareR2AuthenticationMethodSecret OutputCloudflareR2AuthenticationMethod = "secret"
	OutputCloudflareR2AuthenticationMethodManual OutputCloudflareR2AuthenticationMethod = "manual"
)

func (e OutputCloudflareR2AuthenticationMethod) ToPointer() *OutputCloudflareR2AuthenticationMethod {
	return &e
}
func (e *OutputCloudflareR2AuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "secret":
		fallthrough
	case "manual":
		*e = OutputCloudflareR2AuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudflareR2AuthenticationMethod: %v", v)
	}
}

// OutputCloudflareR2SignatureVersion - Signature version to use for signing MinIO requests
type OutputCloudflareR2SignatureVersion string

const (
	OutputCloudflareR2SignatureVersionV2 OutputCloudflareR2SignatureVersion = "v2"
	OutputCloudflareR2SignatureVersionV4 OutputCloudflareR2SignatureVersion = "v4"
)

func (e OutputCloudflareR2SignatureVersion) ToPointer() *OutputCloudflareR2SignatureVersion {
	return &e
}
func (e *OutputCloudflareR2SignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputCloudflareR2SignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudflareR2SignatureVersion: %v", v)
	}
}

// OutputCloudflareR2StorageClass - Storage class to select for uploaded objects
type OutputCloudflareR2StorageClass string

const (
	// OutputCloudflareR2StorageClassStandard Standard
	OutputCloudflareR2StorageClassStandard OutputCloudflareR2StorageClass = "STANDARD"
	// OutputCloudflareR2StorageClassReducedRedundancy Reduced Redundancy Storage
	OutputCloudflareR2StorageClassReducedRedundancy OutputCloudflareR2StorageClass = "REDUCED_REDUNDANCY"
)

func (e OutputCloudflareR2StorageClass) ToPointer() *OutputCloudflareR2StorageClass {
	return &e
}
func (e *OutputCloudflareR2StorageClass) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "STANDARD":
		fallthrough
	case "REDUCED_REDUNDANCY":
		*e = OutputCloudflareR2StorageClass(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudflareR2StorageClass: %v", v)
	}
}

// OutputCloudflareR2ServerSideEncryption - Server-side encryption for uploaded objects
type OutputCloudflareR2ServerSideEncryption string

const (
	// OutputCloudflareR2ServerSideEncryptionAes256 Amazon S3 Managed Key
	OutputCloudflareR2ServerSideEncryptionAes256 OutputCloudflareR2ServerSideEncryption = "AES256"
)

func (e OutputCloudflareR2ServerSideEncryption) ToPointer() *OutputCloudflareR2ServerSideEncryption {
	return &e
}
func (e *OutputCloudflareR2ServerSideEncryption) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "AES256":
		*e = OutputCloudflareR2ServerSideEncryption(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudflareR2ServerSideEncryption: %v", v)
	}
}

// OutputCloudflareR2DataFormat - Format of the output data
type OutputCloudflareR2DataFormat string

const (
	// OutputCloudflareR2DataFormatJSON JSON
	OutputCloudflareR2DataFormatJSON OutputCloudflareR2DataFormat = "json"
	// OutputCloudflareR2DataFormatRaw Raw
	OutputCloudflareR2DataFormatRaw OutputCloudflareR2DataFormat = "raw"
	// OutputCloudflareR2DataFormatParquet Parquet
	OutputCloudflareR2DataFormatParquet OutputCloudflareR2DataFormat = "parquet"
)

func (e OutputCloudflareR2DataFormat) ToPointer() *OutputCloudflareR2DataFormat {
	return &e
}
func (e *OutputCloudflareR2DataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		fallthrough
	case "parquet":
		*e = OutputCloudflareR2DataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudflareR2DataFormat: %v", v)
	}
}

// OutputCloudflareR2BackpressureBehavior - How to handle events when all receivers are exerting backpressure
type OutputCloudflareR2BackpressureBehavior string

const (
	// OutputCloudflareR2BackpressureBehaviorBlock Block
	OutputCloudflareR2BackpressureBehaviorBlock OutputCloudflareR2BackpressureBehavior = "block"
	// OutputCloudflareR2BackpressureBehaviorDrop Drop
	OutputCloudflareR2BackpressureBehaviorDrop OutputCloudflareR2BackpressureBehavior = "drop"
)

func (e OutputCloudflareR2BackpressureBehavior) ToPointer() *OutputCloudflareR2BackpressureBehavior {
	return &e
}
func (e *OutputCloudflareR2BackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputCloudflareR2BackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudflareR2BackpressureBehavior: %v", v)
	}
}

// OutputCloudflareR2DiskSpaceProtection - How to handle events when disk space is below the global 'Min free disk space' limit
type OutputCloudflareR2DiskSpaceProtection string

const (
	// OutputCloudflareR2DiskSpaceProtectionBlock Block
	OutputCloudflareR2DiskSpaceProtectionBlock OutputCloudflareR2DiskSpaceProtection = "block"
	// OutputCloudflareR2DiskSpaceProtectionDrop Drop
	OutputCloudflareR2DiskSpaceProtectionDrop OutputCloudflareR2DiskSpaceProtection = "drop"
)

func (e OutputCloudflareR2DiskSpaceProtection) ToPointer() *OutputCloudflareR2DiskSpaceProtection {
	return &e
}
func (e *OutputCloudflareR2DiskSpaceProtection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputCloudflareR2DiskSpaceProtection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudflareR2DiskSpaceProtection: %v", v)
	}
}

// OutputCloudflareR2Compression - Data compression format to apply to HTTP content before it is delivered
type OutputCloudflareR2Compression string

const (
	OutputCloudflareR2CompressionNone OutputCloudflareR2Compression = "none"
	OutputCloudflareR2CompressionGzip OutputCloudflareR2Compression = "gzip"
)

func (e OutputCloudflareR2Compression) ToPointer() *OutputCloudflareR2Compression {
	return &e
}
func (e *OutputCloudflareR2Compression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputCloudflareR2Compression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudflareR2Compression: %v", v)
	}
}

// OutputCloudflareR2CompressionLevel - Compression level to apply before moving files to final destination
type OutputCloudflareR2CompressionLevel string

const (
	// OutputCloudflareR2CompressionLevelBestSpeed Best Speed
	OutputCloudflareR2CompressionLevelBestSpeed OutputCloudflareR2CompressionLevel = "best_speed"
	// OutputCloudflareR2CompressionLevelNormal Normal
	OutputCloudflareR2CompressionLevelNormal OutputCloudflareR2CompressionLevel = "normal"
	// OutputCloudflareR2CompressionLevelBestCompression Best Compression
	OutputCloudflareR2CompressionLevelBestCompression OutputCloudflareR2CompressionLevel = "best_compression"
)

func (e OutputCloudflareR2CompressionLevel) ToPointer() *OutputCloudflareR2CompressionLevel {
	return &e
}
func (e *OutputCloudflareR2CompressionLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "best_speed":
		fallthrough
	case "normal":
		fallthrough
	case "best_compression":
		*e = OutputCloudflareR2CompressionLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudflareR2CompressionLevel: %v", v)
	}
}

// OutputCloudflareR2ParquetVersion - Determines which data types are supported and how they are represented
type OutputCloudflareR2ParquetVersion string

const (
	// OutputCloudflareR2ParquetVersionParquet10 1.0
	OutputCloudflareR2ParquetVersionParquet10 OutputCloudflareR2ParquetVersion = "PARQUET_1_0"
	// OutputCloudflareR2ParquetVersionParquet24 2.4
	OutputCloudflareR2ParquetVersionParquet24 OutputCloudflareR2ParquetVersion = "PARQUET_2_4"
	// OutputCloudflareR2ParquetVersionParquet26 2.6
	OutputCloudflareR2ParquetVersionParquet26 OutputCloudflareR2ParquetVersion = "PARQUET_2_6"
)

func (e OutputCloudflareR2ParquetVersion) ToPointer() *OutputCloudflareR2ParquetVersion {
	return &e
}
func (e *OutputCloudflareR2ParquetVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PARQUET_1_0":
		fallthrough
	case "PARQUET_2_4":
		fallthrough
	case "PARQUET_2_6":
		*e = OutputCloudflareR2ParquetVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudflareR2ParquetVersion: %v", v)
	}
}

// OutputCloudflareR2DataPageVersion - Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
type OutputCloudflareR2DataPageVersion string

const (
	// OutputCloudflareR2DataPageVersionDataPageV1 V1
	OutputCloudflareR2DataPageVersionDataPageV1 OutputCloudflareR2DataPageVersion = "DATA_PAGE_V1"
	// OutputCloudflareR2DataPageVersionDataPageV2 V2
	OutputCloudflareR2DataPageVersionDataPageV2 OutputCloudflareR2DataPageVersion = "DATA_PAGE_V2"
)

func (e OutputCloudflareR2DataPageVersion) ToPointer() *OutputCloudflareR2DataPageVersion {
	return &e
}
func (e *OutputCloudflareR2DataPageVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "DATA_PAGE_V1":
		fallthrough
	case "DATA_PAGE_V2":
		*e = OutputCloudflareR2DataPageVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputCloudflareR2DataPageVersion: %v", v)
	}
}

type OutputCloudflareR2KeyValueMetadatum struct {
	Key   *string `default:"" json:"key"`
	Value string  `json:"value"`
}

func (o OutputCloudflareR2KeyValueMetadatum) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCloudflareR2KeyValueMetadatum) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"value"}); err != nil {
		return err
	}
	return nil
}

func (o *OutputCloudflareR2KeyValueMetadatum) GetKey() *string {
	if o == nil {
		return nil
	}
	return o.Key
}

func (o *OutputCloudflareR2KeyValueMetadatum) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputCloudflareR2 struct {
	// Unique ID for this output
	ID   *string                `json:"id,omitempty"`
	Type OutputCloudflareR2Type `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Cloudflare R2 service URL (example: https://<ACCOUNT_ID>.r2.cloudflarestorage.com)
	Endpoint string `json:"endpoint"`
	// Name of the destination R2 bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
	Bucket string `json:"bucket"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *OutputCloudflareR2AuthenticationMethod `default:"auto" json:"awsAuthenticationMethod"`
	// Secret key. This value can be a constant or a JavaScript expression, such as `${C.env.SOME_SECRET}`).
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	Region       any     `json:"region,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath *string `default:"$CRIBL_HOME/state/outputs/staging" json:"stagePath"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `default:"true" json:"addIdToStagePath"`
	// Root directory to prepend to path before uploading. Enter a constant, or a JavaScript expression enclosed in quotes or backticks.
	DestPath *string `json:"destPath,omitempty"`
	// Signature version to use for signing MinIO requests
	SignatureVersion *OutputCloudflareR2SignatureVersion `default:"v4" json:"signatureVersion"`
	ObjectACL        any                                 `json:"objectACL,omitempty"`
	// Storage class to select for uploaded objects
	StorageClass *OutputCloudflareR2StorageClass `json:"storageClass,omitempty"`
	// Server-side encryption for uploaded objects
	ServerSideEncryption *OutputCloudflareR2ServerSideEncryption `json:"serverSideEncryption,omitempty"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates)
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Disable if you can access files within the bucket but not the bucket itself
	VerifyPermissions *bool `default:"true" json:"verifyPermissions"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `default:"true" json:"removeEmptyDirs"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `default:"C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')" json:"partitionExpr"`
	// Format of the output data
	Format *OutputCloudflareR2DataFormat `default:"json" json:"format"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `default:"CriblOut" json:"baseFileName"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `default:".\\${C.env[\"CRIBL_WORKER_ID\"]}.\\${__format}\\${__compression === \"gzip\" ? \".gz\" : \"\"}" json:"fileNameSuffix"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `default:"32" json:"maxFileSizeMB"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `default:"100" json:"maxOpenFiles"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `default:"" json:"headerLine"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `default:"64" json:"writeHighWaterMark"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *OutputCloudflareR2BackpressureBehavior `default:"block" json:"onBackpressure"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `default:"false" json:"deadletterEnabled"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *OutputCloudflareR2DiskSpaceProtection `default:"block" json:"onDiskFullBackpressure"`
	// Force all staged files to close during an orderly Node shutdown. This triggers immediate upload of in-progress data — regardless of idle time, file age, or size thresholds — to minimize data loss.
	ForceCloseOnShutdown *bool `default:"false" json:"forceCloseOnShutdown"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `default:"300" json:"maxFileOpenTimeSec"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `default:"30" json:"maxFileIdleTimeSec"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *float64 `default:"4" json:"maxConcurrentFileParts"`
	Description            *string  `json:"description,omitempty"`
	// This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *OutputCloudflareR2Compression `default:"gzip" json:"compress"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *OutputCloudflareR2CompressionLevel `default:"best_speed" json:"compressionLevel"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `default:"false" json:"automaticSchema"`
	// To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
	ParquetSchema *string `json:"parquetSchema,omitempty"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *OutputCloudflareR2ParquetVersion `default:"PARQUET_2_6" json:"parquetVersion"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *OutputCloudflareR2DataPageVersion `default:"DATA_PAGE_V2" json:"parquetDataPageVersion"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `default:"10000" json:"parquetRowGroupLength"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `default:"1MB" json:"parquetPageSize"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []OutputCloudflareR2KeyValueMetadatum `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `default:"true" json:"enableStatistics"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `default:"true" json:"enableWritePageIndex"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `default:"false" json:"enablePageChecksum"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `default:"300" json:"emptyDirCleanupSec"`
	// Number of directories to process in each batch during cleanup of empty directories. Minimum is 10, maximum is 10000. Higher values may require more memory.
	DirectoryBatchSize *float64 `default:"1000" json:"directoryBatchSize"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `default:"$CRIBL_HOME/state/outputs/dead-letter" json:"deadletterPath"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `default:"20" json:"maxRetryNum"`
}

func (o OutputCloudflareR2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputCloudflareR2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"type", "endpoint", "bucket"}); err != nil {
		return err
	}
	return nil
}

func (o *OutputCloudflareR2) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputCloudflareR2) GetType() OutputCloudflareR2Type {
	if o == nil {
		return OutputCloudflareR2Type("")
	}
	return o.Type
}

func (o *OutputCloudflareR2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputCloudflareR2) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputCloudflareR2) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputCloudflareR2) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputCloudflareR2) GetEndpoint() string {
	if o == nil {
		return ""
	}
	return o.Endpoint
}

func (o *OutputCloudflareR2) GetBucket() string {
	if o == nil {
		return ""
	}
	return o.Bucket
}

func (o *OutputCloudflareR2) GetAwsAuthenticationMethod() *OutputCloudflareR2AuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *OutputCloudflareR2) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *OutputCloudflareR2) GetRegion() any {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *OutputCloudflareR2) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputCloudflareR2) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputCloudflareR2) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputCloudflareR2) GetSignatureVersion() *OutputCloudflareR2SignatureVersion {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *OutputCloudflareR2) GetObjectACL() any {
	if o == nil {
		return nil
	}
	return o.ObjectACL
}

func (o *OutputCloudflareR2) GetStorageClass() *OutputCloudflareR2StorageClass {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputCloudflareR2) GetServerSideEncryption() *OutputCloudflareR2ServerSideEncryption {
	if o == nil {
		return nil
	}
	return o.ServerSideEncryption
}

func (o *OutputCloudflareR2) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *OutputCloudflareR2) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputCloudflareR2) GetVerifyPermissions() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyPermissions
}

func (o *OutputCloudflareR2) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputCloudflareR2) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputCloudflareR2) GetFormat() *OutputCloudflareR2DataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputCloudflareR2) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputCloudflareR2) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputCloudflareR2) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputCloudflareR2) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputCloudflareR2) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputCloudflareR2) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputCloudflareR2) GetOnBackpressure() *OutputCloudflareR2BackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputCloudflareR2) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputCloudflareR2) GetOnDiskFullBackpressure() *OutputCloudflareR2DiskSpaceProtection {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputCloudflareR2) GetForceCloseOnShutdown() *bool {
	if o == nil {
		return nil
	}
	return o.ForceCloseOnShutdown
}

func (o *OutputCloudflareR2) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputCloudflareR2) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputCloudflareR2) GetMaxConcurrentFileParts() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentFileParts
}

func (o *OutputCloudflareR2) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputCloudflareR2) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *OutputCloudflareR2) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *OutputCloudflareR2) GetCompress() *OutputCloudflareR2Compression {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputCloudflareR2) GetCompressionLevel() *OutputCloudflareR2CompressionLevel {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

func (o *OutputCloudflareR2) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputCloudflareR2) GetParquetSchema() *string {
	if o == nil {
		return nil
	}
	return o.ParquetSchema
}

func (o *OutputCloudflareR2) GetParquetVersion() *OutputCloudflareR2ParquetVersion {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputCloudflareR2) GetParquetDataPageVersion() *OutputCloudflareR2DataPageVersion {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputCloudflareR2) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputCloudflareR2) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputCloudflareR2) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputCloudflareR2) GetKeyValueMetadata() []OutputCloudflareR2KeyValueMetadatum {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputCloudflareR2) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputCloudflareR2) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputCloudflareR2) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputCloudflareR2) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputCloudflareR2) GetDirectoryBatchSize() *float64 {
	if o == nil {
		return nil
	}
	return o.DirectoryBatchSize
}

func (o *OutputCloudflareR2) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputCloudflareR2) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}
