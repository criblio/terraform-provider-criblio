// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
	"github.com/criblio/terraform-provider-criblio/internal/sdk/internal/utils"
)

type InputCollectorDatabaseTypeCollection1 string

const (
	InputCollectorDatabaseTypeCollection1Collection InputCollectorDatabaseTypeCollection1 = "collection"
)

func (e InputCollectorDatabaseTypeCollection1) ToPointer() *InputCollectorDatabaseTypeCollection1 {
	return &e
}
func (e *InputCollectorDatabaseTypeCollection1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "collection":
		*e = InputCollectorDatabaseTypeCollection1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectorDatabaseTypeCollection1: %v", v)
	}
}

// InputCollectorDatabaseSavedState - Saved state for the collector
type InputCollectorDatabaseSavedState struct {
}

func (i InputCollectorDatabaseSavedState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorDatabaseSavedState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

// InputCollectorDatabaseLogLevel - Level at which to set task logging
type InputCollectorDatabaseLogLevel string

const (
	InputCollectorDatabaseLogLevelError InputCollectorDatabaseLogLevel = "error"
	InputCollectorDatabaseLogLevelWarn  InputCollectorDatabaseLogLevel = "warn"
	InputCollectorDatabaseLogLevelInfo  InputCollectorDatabaseLogLevel = "info"
	InputCollectorDatabaseLogLevelDebug InputCollectorDatabaseLogLevel = "debug"
	InputCollectorDatabaseLogLevelSilly InputCollectorDatabaseLogLevel = "silly"
)

func (e InputCollectorDatabaseLogLevel) ToPointer() *InputCollectorDatabaseLogLevel {
	return &e
}
func (e *InputCollectorDatabaseLogLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		fallthrough
	case "silly":
		*e = InputCollectorDatabaseLogLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectorDatabaseLogLevel: %v", v)
	}
}

// InputCollectorDatabaseMode - Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.
type InputCollectorDatabaseMode string

const (
	InputCollectorDatabaseModeList    InputCollectorDatabaseMode = "list"
	InputCollectorDatabaseModePreview InputCollectorDatabaseMode = "preview"
	InputCollectorDatabaseModeRun     InputCollectorDatabaseMode = "run"
)

func (e InputCollectorDatabaseMode) ToPointer() *InputCollectorDatabaseMode {
	return &e
}
func (e *InputCollectorDatabaseMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "list":
		fallthrough
	case "preview":
		fallthrough
	case "run":
		*e = InputCollectorDatabaseMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectorDatabaseMode: %v", v)
	}
}

type InputCollectorDatabaseTimeRange string

const (
	InputCollectorDatabaseTimeRangeRelative InputCollectorDatabaseTimeRange = "relative"
	InputCollectorDatabaseTimeRangeAbsolute InputCollectorDatabaseTimeRange = "absolute"
)

func (e InputCollectorDatabaseTimeRange) ToPointer() *InputCollectorDatabaseTimeRange {
	return &e
}
func (e *InputCollectorDatabaseTimeRange) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "relative":
		fallthrough
	case "absolute":
		*e = InputCollectorDatabaseTimeRange(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectorDatabaseTimeRange: %v", v)
	}
}

// InputCollectorDatabaseTimeWarning - Time warning configuration
type InputCollectorDatabaseTimeWarning struct {
}

func (i InputCollectorDatabaseTimeWarning) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorDatabaseTimeWarning) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

// InputCollectorDatabaseStateTracking - State tracking configuration
type InputCollectorDatabaseStateTracking struct {
	StateUpdateExpression *string `json:"stateUpdateExpression,omitempty"`
	StateMergeExpression  *string `json:"stateMergeExpression,omitempty"`
	Enabled               *bool   `default:"false" json:"enabled"`
}

func (i InputCollectorDatabaseStateTracking) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorDatabaseStateTracking) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorDatabaseStateTracking) GetStateUpdateExpression() *string {
	if o == nil {
		return nil
	}
	return o.StateUpdateExpression
}

func (o *InputCollectorDatabaseStateTracking) GetStateMergeExpression() *string {
	if o == nil {
		return nil
	}
	return o.StateMergeExpression
}

func (o *InputCollectorDatabaseStateTracking) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

type InputCollectorDatabaseRunSettings struct {
	// Reschedule tasks that failed with non-fatal errors
	RescheduleDroppedTasks *bool `default:"true" json:"rescheduleDroppedTasks"`
	// Maximum number of times a task can be rescheduled
	MaxTaskReschedule *float64 `default:"1" json:"maxTaskReschedule"`
	// Level at which to set task logging
	LogLevel *InputCollectorDatabaseLogLevel `default:"info" json:"logLevel"`
	// Maximum time the job is allowed to run. Time unit defaults to seconds if not specified (examples: 30, 45s, 15m). Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.
	Mode          *InputCollectorDatabaseMode      `default:"list" json:"mode"`
	TimeRangeType *InputCollectorDatabaseTimeRange `default:"relative" json:"timeRangeType"`
	// Earliest time to collect data for the selected timezone
	Earliest *float64 `default:"0" json:"earliest"`
	// Latest time to collect data for the selected timezone
	Latest *float64 `default:"1" json:"latest"`
	// A filter for tokens in the provided collect path and/or the events being collected
	Expression *string `default:"true" json:"expression"`
	// Limits the bundle size for small tasks. For example, if your lower bundle size is 1MB, you can bundle up to five 200KB files into one task.
	MinTaskSize *string `default:"1MB" json:"minTaskSize"`
	// Limits the bundle size for files above the lower task bundle size. For example, if your upper bundle size is 10MB, you can bundle up to five 2MB files into one task. Files greater than this size will be assigned to individual tasks.
	MaxTaskSize *string `default:"10MB" json:"maxTaskSize"`
	// Time warning configuration
	TimeWarning *InputCollectorDatabaseTimeWarning `json:"timeWarning,omitempty"`
	// State tracking configuration
	StateTracking *InputCollectorDatabaseStateTracking `json:"stateTracking,omitempty"`
}

func (i InputCollectorDatabaseRunSettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorDatabaseRunSettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorDatabaseRunSettings) GetRescheduleDroppedTasks() *bool {
	if o == nil {
		return nil
	}
	return o.RescheduleDroppedTasks
}

func (o *InputCollectorDatabaseRunSettings) GetMaxTaskReschedule() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxTaskReschedule
}

func (o *InputCollectorDatabaseRunSettings) GetLogLevel() *InputCollectorDatabaseLogLevel {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *InputCollectorDatabaseRunSettings) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputCollectorDatabaseRunSettings) GetMode() *InputCollectorDatabaseMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputCollectorDatabaseRunSettings) GetTimeRangeType() *InputCollectorDatabaseTimeRange {
	if o == nil {
		return nil
	}
	return o.TimeRangeType
}

func (o *InputCollectorDatabaseRunSettings) GetEarliest() *float64 {
	if o == nil {
		return nil
	}
	return o.Earliest
}

func (o *InputCollectorDatabaseRunSettings) GetLatest() *float64 {
	if o == nil {
		return nil
	}
	return o.Latest
}

func (o *InputCollectorDatabaseRunSettings) GetExpression() *string {
	if o == nil {
		return nil
	}
	return o.Expression
}

func (o *InputCollectorDatabaseRunSettings) GetMinTaskSize() *string {
	if o == nil {
		return nil
	}
	return o.MinTaskSize
}

func (o *InputCollectorDatabaseRunSettings) GetMaxTaskSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxTaskSize
}

func (o *InputCollectorDatabaseRunSettings) GetTimeWarning() *InputCollectorDatabaseTimeWarning {
	if o == nil {
		return nil
	}
	return o.TimeWarning
}

func (o *InputCollectorDatabaseRunSettings) GetStateTracking() *InputCollectorDatabaseStateTracking {
	if o == nil {
		return nil
	}
	return o.StateTracking
}

// InputCollectorDatabaseSchedule - Configuration for a scheduled job
type InputCollectorDatabaseSchedule struct {
	// Enable to configure scheduling for this Collector
	Enabled *bool `json:"enabled,omitempty"`
	// A cron schedule on which to run this job
	CronSchedule *string `default:"*/5 * * * *" json:"cronSchedule"`
	// The maximum number of instances of this scheduled job that may be running at any time
	MaxConcurrentRuns *float64 `default:"1" json:"maxConcurrentRuns"`
	// Skippable jobs can be delayed, up to their next run time, if the system is hitting concurrency limits
	Skippable *bool `default:"true" json:"skippable"`
	// Resume missed scheduled runs
	ResumeMissed *bool                              `default:"false" json:"resumeMissed"`
	Run          *InputCollectorDatabaseRunSettings `json:"run,omitempty"`
}

func (i InputCollectorDatabaseSchedule) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorDatabaseSchedule) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorDatabaseSchedule) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *InputCollectorDatabaseSchedule) GetCronSchedule() *string {
	if o == nil {
		return nil
	}
	return o.CronSchedule
}

func (o *InputCollectorDatabaseSchedule) GetMaxConcurrentRuns() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentRuns
}

func (o *InputCollectorDatabaseSchedule) GetSkippable() *bool {
	if o == nil {
		return nil
	}
	return o.Skippable
}

func (o *InputCollectorDatabaseSchedule) GetResumeMissed() *bool {
	if o == nil {
		return nil
	}
	return o.ResumeMissed
}

func (o *InputCollectorDatabaseSchedule) GetRun() *InputCollectorDatabaseRunSettings {
	if o == nil {
		return nil
	}
	return o.Run
}

type InputCollectorDatabaseTypeCollection2 string

const (
	InputCollectorDatabaseTypeCollection2Collection InputCollectorDatabaseTypeCollection2 = "collection"
)

func (e InputCollectorDatabaseTypeCollection2) ToPointer() *InputCollectorDatabaseTypeCollection2 {
	return &e
}
func (e *InputCollectorDatabaseTypeCollection2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "collection":
		*e = InputCollectorDatabaseTypeCollection2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectorDatabaseTypeCollection2: %v", v)
	}
}

type InputCollectorDatabasePreprocess struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (i InputCollectorDatabasePreprocess) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorDatabasePreprocess) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorDatabasePreprocess) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCollectorDatabasePreprocess) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *InputCollectorDatabasePreprocess) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type InputCollectorDatabaseMetadatum struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (i InputCollectorDatabaseMetadatum) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorDatabaseMetadatum) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorDatabaseMetadatum) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputCollectorDatabaseMetadatum) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCollectorDatabaseInput struct {
	Type *InputCollectorDatabaseTypeCollection2 `default:"collection" json:"type"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
	SendToRoutes *bool                             `default:"true" json:"sendToRoutes"`
	Preprocess   *InputCollectorDatabasePreprocess `json:"preprocess,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `default:"0" json:"throttleRatePerSec"`
	// Fields to add to events from this input
	Metadata []InputCollectorDatabaseMetadatum `json:"metadata,omitempty"`
	// Pipeline to process results
	Pipeline *string `json:"pipeline,omitempty"`
	// Destination to send results to
	Output *string `json:"output,omitempty"`
}

func (i InputCollectorDatabaseInput) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorDatabaseInput) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorDatabaseInput) GetType() *InputCollectorDatabaseTypeCollection2 {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputCollectorDatabaseInput) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputCollectorDatabaseInput) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputCollectorDatabaseInput) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCollectorDatabaseInput) GetPreprocess() *InputCollectorDatabasePreprocess {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputCollectorDatabaseInput) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *InputCollectorDatabaseInput) GetMetadata() []InputCollectorDatabaseMetadatum {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCollectorDatabaseInput) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCollectorDatabaseInput) GetOutput() *string {
	if o == nil {
		return nil
	}
	return o.Output
}

type TypeDatabase string

const (
	TypeDatabaseDatabase TypeDatabase = "database"
)

func (e TypeDatabase) ToPointer() *TypeDatabase {
	return &e
}
func (e *TypeDatabase) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "database":
		*e = TypeDatabase(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDatabase: %v", v)
	}
}

type InputCollectorDatabaseConf struct {
	// Select an existing Database Connection
	ConnectionID *string `json:"connectionId,omitempty"`
	// Query string for selecting data from the database
	Query                  *string `json:"query,omitempty"`
	QueryValidationEnabled *bool   `json:"queryValidationEnabled,omitempty"`
}

func (i InputCollectorDatabaseConf) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorDatabaseConf) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorDatabaseConf) GetConnectionID() *string {
	if o == nil {
		return nil
	}
	return o.ConnectionID
}

func (o *InputCollectorDatabaseConf) GetQuery() *string {
	if o == nil {
		return nil
	}
	return o.Query
}

func (o *InputCollectorDatabaseConf) GetQueryValidationEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.QueryValidationEnabled
}

type InputCollectorDatabaseCollector struct {
	Type TypeDatabase                `json:"type"`
	Conf *InputCollectorDatabaseConf `json:"conf,omitempty"`
}

func (i InputCollectorDatabaseCollector) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorDatabaseCollector) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorDatabaseCollector) GetType() TypeDatabase {
	if o == nil {
		return TypeDatabase("")
	}
	return o.Type
}

func (o *InputCollectorDatabaseCollector) GetConf() *InputCollectorDatabaseConf {
	if o == nil {
		return nil
	}
	return o.Conf
}

type InputCollectorDatabase struct {
	ID                   *string                                `json:"id,omitempty"`
	Type                 *InputCollectorDatabaseTypeCollection1 `default:"collection" json:"type"`
	TTL                  *string                                `default:"4h" json:"ttl"`
	IgnoreGroupJobsLimit *bool                                  `default:"false" json:"ignoreGroupJobsLimit"`
	RemoveFields         []string                               `json:"removeFields,omitempty"`
	ResumeOnBoot         *bool                                  `default:"true" json:"resumeOnBoot"`
	Environment          *string                                `json:"environment,omitempty"`
	// Saved state for the collector
	SavedState *InputCollectorDatabaseSavedState `json:"savedState,omitempty"`
	// Configuration for a scheduled job
	Schedule *InputCollectorDatabaseSchedule `json:"schedule,omitempty"`
	// Tags for filtering and grouping
	Streamtags []string `json:"streamtags,omitempty"`
	// If enabled, tasks are created and run by the same Worker Node
	WorkerAffinity *bool                           `default:"false" json:"workerAffinity"`
	Input          *InputCollectorDatabaseInput    `json:"input,omitempty"`
	Collector      InputCollectorDatabaseCollector `json:"collector"`
}

func (i InputCollectorDatabase) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorDatabase) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"collector"}); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorDatabase) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputCollectorDatabase) GetType() *InputCollectorDatabaseTypeCollection1 {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputCollectorDatabase) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputCollectorDatabase) GetIgnoreGroupJobsLimit() *bool {
	if o == nil {
		return nil
	}
	return o.IgnoreGroupJobsLimit
}

func (o *InputCollectorDatabase) GetRemoveFields() []string {
	if o == nil {
		return nil
	}
	return o.RemoveFields
}

func (o *InputCollectorDatabase) GetResumeOnBoot() *bool {
	if o == nil {
		return nil
	}
	return o.ResumeOnBoot
}

func (o *InputCollectorDatabase) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCollectorDatabase) GetSavedState() *InputCollectorDatabaseSavedState {
	if o == nil {
		return nil
	}
	return o.SavedState
}

func (o *InputCollectorDatabase) GetSchedule() *InputCollectorDatabaseSchedule {
	if o == nil {
		return nil
	}
	return o.Schedule
}

func (o *InputCollectorDatabase) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCollectorDatabase) GetWorkerAffinity() *bool {
	if o == nil {
		return nil
	}
	return o.WorkerAffinity
}

func (o *InputCollectorDatabase) GetInput() *InputCollectorDatabaseInput {
	if o == nil {
		return nil
	}
	return o.Input
}

func (o *InputCollectorDatabase) GetCollector() InputCollectorDatabaseCollector {
	if o == nil {
		return InputCollectorDatabaseCollector{}
	}
	return o.Collector
}
