// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
	"github.com/criblio/terraform-provider-criblio/internal/sdk/internal/utils"
)

type OutputChronicleType string

const (
	OutputChronicleTypeChronicle OutputChronicleType = "chronicle"
)

func (e OutputChronicleType) ToPointer() *OutputChronicleType {
	return &e
}
func (e *OutputChronicleType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "chronicle":
		*e = OutputChronicleType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputChronicleType: %v", v)
	}
}

type OutputChronicleAuthenticationMethod string

const (
	OutputChronicleAuthenticationMethodServiceAccount       OutputChronicleAuthenticationMethod = "serviceAccount"
	OutputChronicleAuthenticationMethodServiceAccountSecret OutputChronicleAuthenticationMethod = "serviceAccountSecret"
)

func (e OutputChronicleAuthenticationMethod) ToPointer() *OutputChronicleAuthenticationMethod {
	return &e
}
func (e *OutputChronicleAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "serviceAccount":
		fallthrough
	case "serviceAccountSecret":
		*e = OutputChronicleAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputChronicleAuthenticationMethod: %v", v)
	}
}

type OutputChronicleResponseRetrySetting struct {
	// The HTTP response status code that will trigger retries
	HTTPStatus float64 `json:"httpStatus"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputChronicleResponseRetrySetting) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputChronicleResponseRetrySetting) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"httpStatus"}); err != nil {
		return err
	}
	return nil
}

func (o *OutputChronicleResponseRetrySetting) GetHTTPStatus() float64 {
	if o == nil {
		return 0.0
	}
	return o.HTTPStatus
}

func (o *OutputChronicleResponseRetrySetting) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputChronicleResponseRetrySetting) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputChronicleResponseRetrySetting) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputChronicleTimeoutRetrySettings struct {
	TimeoutRetry *bool `default:"false" json:"timeoutRetry"`
	// How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"1000" json:"initialBackoff"`
	// Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackoff *float64 `default:"10000" json:"maxBackoff"`
}

func (o OutputChronicleTimeoutRetrySettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputChronicleTimeoutRetrySettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *OutputChronicleTimeoutRetrySettings) GetTimeoutRetry() *bool {
	if o == nil {
		return nil
	}
	return o.TimeoutRetry
}

func (o *OutputChronicleTimeoutRetrySettings) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *OutputChronicleTimeoutRetrySettings) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *OutputChronicleTimeoutRetrySettings) GetMaxBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackoff
}

type OutputChronicleExtraHTTPHeader struct {
	Name  *string `json:"name,omitempty"`
	Value string  `json:"value"`
}

func (o OutputChronicleExtraHTTPHeader) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputChronicleExtraHTTPHeader) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"value"}); err != nil {
		return err
	}
	return nil
}

func (o *OutputChronicleExtraHTTPHeader) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *OutputChronicleExtraHTTPHeader) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// OutputChronicleFailedRequestLoggingMode - Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
type OutputChronicleFailedRequestLoggingMode string

const (
	// OutputChronicleFailedRequestLoggingModePayload Payload
	OutputChronicleFailedRequestLoggingModePayload OutputChronicleFailedRequestLoggingMode = "payload"
	// OutputChronicleFailedRequestLoggingModePayloadAndHeaders Payload + Headers
	OutputChronicleFailedRequestLoggingModePayloadAndHeaders OutputChronicleFailedRequestLoggingMode = "payloadAndHeaders"
	// OutputChronicleFailedRequestLoggingModeNone None
	OutputChronicleFailedRequestLoggingModeNone OutputChronicleFailedRequestLoggingMode = "none"
)

func (e OutputChronicleFailedRequestLoggingMode) ToPointer() *OutputChronicleFailedRequestLoggingMode {
	return &e
}
func (e *OutputChronicleFailedRequestLoggingMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "payload":
		fallthrough
	case "payloadAndHeaders":
		fallthrough
	case "none":
		*e = OutputChronicleFailedRequestLoggingMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputChronicleFailedRequestLoggingMode: %v", v)
	}
}

// OutputChronicleBackpressureBehavior - How to handle events when all receivers are exerting backpressure
type OutputChronicleBackpressureBehavior string

const (
	// OutputChronicleBackpressureBehaviorBlock Block
	OutputChronicleBackpressureBehaviorBlock OutputChronicleBackpressureBehavior = "block"
	// OutputChronicleBackpressureBehaviorDrop Drop
	OutputChronicleBackpressureBehaviorDrop OutputChronicleBackpressureBehavior = "drop"
	// OutputChronicleBackpressureBehaviorQueue Persistent Queue
	OutputChronicleBackpressureBehaviorQueue OutputChronicleBackpressureBehavior = "queue"
)

func (e OutputChronicleBackpressureBehavior) ToPointer() *OutputChronicleBackpressureBehavior {
	return &e
}
func (e *OutputChronicleBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		fallthrough
	case "queue":
		*e = OutputChronicleBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputChronicleBackpressureBehavior: %v", v)
	}
}

type OutputChronicleCustomLabel struct {
	Key   string `json:"key"`
	Value string `json:"value"`
	// Designate this label for role-based access control and filtering
	RbacEnabled *bool `default:"false" json:"rbacEnabled"`
}

func (o OutputChronicleCustomLabel) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputChronicleCustomLabel) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"key", "value"}); err != nil {
		return err
	}
	return nil
}

func (o *OutputChronicleCustomLabel) GetKey() string {
	if o == nil {
		return ""
	}
	return o.Key
}

func (o *OutputChronicleCustomLabel) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

func (o *OutputChronicleCustomLabel) GetRbacEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.RbacEnabled
}

// OutputChronicleMode - In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
type OutputChronicleMode string

const (
	// OutputChronicleModeError Error
	OutputChronicleModeError OutputChronicleMode = "error"
	// OutputChronicleModeAlways Backpressure
	OutputChronicleModeAlways OutputChronicleMode = "always"
	// OutputChronicleModeBackpressure Always On
	OutputChronicleModeBackpressure OutputChronicleMode = "backpressure"
)

func (e OutputChronicleMode) ToPointer() *OutputChronicleMode {
	return &e
}
func (e *OutputChronicleMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "always":
		fallthrough
	case "backpressure":
		*e = OutputChronicleMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputChronicleMode: %v", v)
	}
}

// OutputChronicleCompression - Codec to use to compress the persisted data
type OutputChronicleCompression string

const (
	// OutputChronicleCompressionNone None
	OutputChronicleCompressionNone OutputChronicleCompression = "none"
	// OutputChronicleCompressionGzip Gzip
	OutputChronicleCompressionGzip OutputChronicleCompression = "gzip"
)

func (e OutputChronicleCompression) ToPointer() *OutputChronicleCompression {
	return &e
}
func (e *OutputChronicleCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputChronicleCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputChronicleCompression: %v", v)
	}
}

// OutputChronicleQueueFullBehavior - How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputChronicleQueueFullBehavior string

const (
	// OutputChronicleQueueFullBehaviorBlock Block
	OutputChronicleQueueFullBehaviorBlock OutputChronicleQueueFullBehavior = "block"
	// OutputChronicleQueueFullBehaviorDrop Drop new data
	OutputChronicleQueueFullBehaviorDrop OutputChronicleQueueFullBehavior = "drop"
)

func (e OutputChronicleQueueFullBehavior) ToPointer() *OutputChronicleQueueFullBehavior {
	return &e
}
func (e *OutputChronicleQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputChronicleQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputChronicleQueueFullBehavior: %v", v)
	}
}

type OutputChroniclePqControls struct {
}

func (o OutputChroniclePqControls) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputChroniclePqControls) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, nil); err != nil {
		return err
	}
	return nil
}

type OutputChronicle struct {
	// Unique ID for this output
	ID   *string             `json:"id,omitempty"`
	Type OutputChronicleType `json:"type"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags           []string                             `json:"streamtags,omitempty"`
	APIVersion           *string                              `default:"v1alpha" json:"apiVersion"`
	AuthenticationMethod *OutputChronicleAuthenticationMethod `default:"serviceAccount" json:"authenticationMethod"`
	// Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable)
	ResponseRetrySettings []OutputChronicleResponseRetrySetting `json:"responseRetrySettings,omitempty"`
	TimeoutRetrySettings  *OutputChronicleTimeoutRetrySettings  `json:"timeoutRetrySettings,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
	ResponseHonorRetryAfterHeader *bool `default:"true" json:"responseHonorRetryAfterHeader"`
	// Regional endpoint to send events to
	Region string `json:"region"`
	// Maximum number of ongoing requests before blocking
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Maximum size, in KB, of the request body
	MaxPayloadSizeKB *float64 `default:"1024" json:"maxPayloadSizeKB"`
	// Maximum number of events to include in the request body. Default is 0 (unlimited).
	MaxPayloadEvents *float64 `default:"0" json:"maxPayloadEvents"`
	// Compress the payload body before sending
	Compress *bool `default:"true" json:"compress"`
	// Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's).
	//         Enabled by default. When this setting is also present in TLS Settings (Client Side),
	//         that value will take precedence.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Amount of time, in seconds, to wait for a request to complete before canceling it
	TimeoutSec *float64 `default:"90" json:"timeoutSec"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
	FlushPeriodSec *float64 `default:"1" json:"flushPeriodSec"`
	// Headers to add to all events
	ExtraHTTPHeaders []OutputChronicleExtraHTTPHeader `json:"extraHttpHeaders,omitempty"`
	// Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
	FailedRequestLoggingMode *OutputChronicleFailedRequestLoggingMode `default:"none" json:"failedRequestLoggingMode"`
	// List of headers that are safe to log in plain text
	SafeHeaders []string `json:"safeHeaders,omitempty"`
	// Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned.
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *OutputChronicleBackpressureBehavior `default:"block" json:"onBackpressure"`
	// Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
	TotalMemoryLimitKB *float64 `json:"totalMemoryLimitKB,omitempty"`
	IngestionMethod    *string  `default:"ImportLogs" json:"ingestionMethod"`
	// User-configured environment namespace to identify the data domain the logs originated from. This namespace is used as a tag to identify the appropriate data domain for indexing and enrichment functionality. Can be overwritten by event field __namespace.
	Namespace *string `json:"namespace,omitempty"`
	// Default log type value to send to SecOps. Can be overwritten by event field __logType.
	LogType string `json:"logType"`
	// Name of the event field that contains the log text to send. If not specified, Stream sends a JSON representation of the whole event.
	LogTextField *string `json:"logTextField,omitempty"`
	// The Google Cloud Platform (GCP) project ID to send events to
	GcpProjectID string `json:"gcpProjectId"`
	// The Google Cloud Platform (GCP) instance to send events to. This is the Chronicle customer uuid.
	GcpInstance string `json:"gcpInstance"`
	// Custom labels to be added to every event
	CustomLabels []OutputChronicleCustomLabel `json:"customLabels,omitempty"`
	Description  *string                      `json:"description,omitempty"`
	// Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
	ServiceAccountCredentials *string `json:"serviceAccountCredentials,omitempty"`
	// Select or create a stored text secret
	ServiceAccountCredentialsSecret *string `json:"serviceAccountCredentialsSecret,omitempty"`
	// Use FIFO (first in, first out) processing. Disable to forward new events to receivers before queue is flushed.
	PqStrictOrdering *bool `default:"true" json:"pqStrictOrdering"`
	// Throttling rate (in events per second) to impose while writing to Destinations from PQ. Defaults to 0, which disables throttling.
	PqRatePerSec *float64 `default:"0" json:"pqRatePerSec"`
	// In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
	PqMode *OutputChronicleMode `default:"error" json:"pqMode"`
	// The maximum number of events to hold in memory before writing the events to disk
	PqMaxBufferSize *float64 `default:"42" json:"pqMaxBufferSize"`
	// How long (in seconds) to wait for backpressure to resolve before engaging the queue
	PqMaxBackpressureSec *float64 `default:"30" json:"pqMaxBackpressureSec"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
	PqMaxFileSize *string `default:"1 MB" json:"pqMaxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `default:"5GB" json:"pqMaxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `default:"$CRIBL_HOME/state/queues" json:"pqPath"`
	// Codec to use to compress the persisted data
	PqCompress *OutputChronicleCompression `default:"none" json:"pqCompress"`
	// How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputChronicleQueueFullBehavior `default:"block" json:"pqOnBackpressure"`
	PqControls       *OutputChroniclePqControls        `json:"pqControls,omitempty"`
}

func (o OutputChronicle) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputChronicle) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"type", "region", "logType", "gcpProjectId", "gcpInstance"}); err != nil {
		return err
	}
	return nil
}

func (o *OutputChronicle) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputChronicle) GetType() OutputChronicleType {
	if o == nil {
		return OutputChronicleType("")
	}
	return o.Type
}

func (o *OutputChronicle) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputChronicle) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputChronicle) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputChronicle) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputChronicle) GetAPIVersion() *string {
	if o == nil {
		return nil
	}
	return o.APIVersion
}

func (o *OutputChronicle) GetAuthenticationMethod() *OutputChronicleAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthenticationMethod
}

func (o *OutputChronicle) GetResponseRetrySettings() []OutputChronicleResponseRetrySetting {
	if o == nil {
		return nil
	}
	return o.ResponseRetrySettings
}

func (o *OutputChronicle) GetTimeoutRetrySettings() *OutputChronicleTimeoutRetrySettings {
	if o == nil {
		return nil
	}
	return o.TimeoutRetrySettings
}

func (o *OutputChronicle) GetResponseHonorRetryAfterHeader() *bool {
	if o == nil {
		return nil
	}
	return o.ResponseHonorRetryAfterHeader
}

func (o *OutputChronicle) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *OutputChronicle) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *OutputChronicle) GetMaxPayloadSizeKB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadSizeKB
}

func (o *OutputChronicle) GetMaxPayloadEvents() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxPayloadEvents
}

func (o *OutputChronicle) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputChronicle) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *OutputChronicle) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *OutputChronicle) GetFlushPeriodSec() *float64 {
	if o == nil {
		return nil
	}
	return o.FlushPeriodSec
}

func (o *OutputChronicle) GetExtraHTTPHeaders() []OutputChronicleExtraHTTPHeader {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *OutputChronicle) GetFailedRequestLoggingMode() *OutputChronicleFailedRequestLoggingMode {
	if o == nil {
		return nil
	}
	return o.FailedRequestLoggingMode
}

func (o *OutputChronicle) GetSafeHeaders() []string {
	if o == nil {
		return nil
	}
	return o.SafeHeaders
}

func (o *OutputChronicle) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *OutputChronicle) GetOnBackpressure() *OutputChronicleBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputChronicle) GetTotalMemoryLimitKB() *float64 {
	if o == nil {
		return nil
	}
	return o.TotalMemoryLimitKB
}

func (o *OutputChronicle) GetIngestionMethod() *string {
	if o == nil {
		return nil
	}
	return o.IngestionMethod
}

func (o *OutputChronicle) GetNamespace() *string {
	if o == nil {
		return nil
	}
	return o.Namespace
}

func (o *OutputChronicle) GetLogType() string {
	if o == nil {
		return ""
	}
	return o.LogType
}

func (o *OutputChronicle) GetLogTextField() *string {
	if o == nil {
		return nil
	}
	return o.LogTextField
}

func (o *OutputChronicle) GetGcpProjectID() string {
	if o == nil {
		return ""
	}
	return o.GcpProjectID
}

func (o *OutputChronicle) GetGcpInstance() string {
	if o == nil {
		return ""
	}
	return o.GcpInstance
}

func (o *OutputChronicle) GetCustomLabels() []OutputChronicleCustomLabel {
	if o == nil {
		return nil
	}
	return o.CustomLabels
}

func (o *OutputChronicle) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputChronicle) GetServiceAccountCredentials() *string {
	if o == nil {
		return nil
	}
	return o.ServiceAccountCredentials
}

func (o *OutputChronicle) GetServiceAccountCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.ServiceAccountCredentialsSecret
}

func (o *OutputChronicle) GetPqStrictOrdering() *bool {
	if o == nil {
		return nil
	}
	return o.PqStrictOrdering
}

func (o *OutputChronicle) GetPqRatePerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqRatePerSec
}

func (o *OutputChronicle) GetPqMode() *OutputChronicleMode {
	if o == nil {
		return nil
	}
	return o.PqMode
}

func (o *OutputChronicle) GetPqMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBufferSize
}

func (o *OutputChronicle) GetPqMaxBackpressureSec() *float64 {
	if o == nil {
		return nil
	}
	return o.PqMaxBackpressureSec
}

func (o *OutputChronicle) GetPqMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxFileSize
}

func (o *OutputChronicle) GetPqMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.PqMaxSize
}

func (o *OutputChronicle) GetPqPath() *string {
	if o == nil {
		return nil
	}
	return o.PqPath
}

func (o *OutputChronicle) GetPqCompress() *OutputChronicleCompression {
	if o == nil {
		return nil
	}
	return o.PqCompress
}

func (o *OutputChronicle) GetPqOnBackpressure() *OutputChronicleQueueFullBehavior {
	if o == nil {
		return nil
	}
	return o.PqOnBackpressure
}

func (o *OutputChronicle) GetPqControls() *OutputChroniclePqControls {
	if o == nil {
		return nil
	}
	return o.PqControls
}
