// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
	"github.com/criblio/terraform-provider-criblio/internal/sdk/internal/utils"
)

type InputCollectorCriblLakeTypeCollection1 string

const (
	InputCollectorCriblLakeTypeCollection1Collection InputCollectorCriblLakeTypeCollection1 = "collection"
)

func (e InputCollectorCriblLakeTypeCollection1) ToPointer() *InputCollectorCriblLakeTypeCollection1 {
	return &e
}
func (e *InputCollectorCriblLakeTypeCollection1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "collection":
		*e = InputCollectorCriblLakeTypeCollection1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectorCriblLakeTypeCollection1: %v", v)
	}
}

// InputCollectorCriblLakeSavedState - Saved state for the collector
type InputCollectorCriblLakeSavedState struct {
}

func (i InputCollectorCriblLakeSavedState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorCriblLakeSavedState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

// InputCollectorCriblLakeLogLevel - Level at which to set task logging
type InputCollectorCriblLakeLogLevel string

const (
	InputCollectorCriblLakeLogLevelError InputCollectorCriblLakeLogLevel = "error"
	InputCollectorCriblLakeLogLevelWarn  InputCollectorCriblLakeLogLevel = "warn"
	InputCollectorCriblLakeLogLevelInfo  InputCollectorCriblLakeLogLevel = "info"
	InputCollectorCriblLakeLogLevelDebug InputCollectorCriblLakeLogLevel = "debug"
	InputCollectorCriblLakeLogLevelSilly InputCollectorCriblLakeLogLevel = "silly"
)

func (e InputCollectorCriblLakeLogLevel) ToPointer() *InputCollectorCriblLakeLogLevel {
	return &e
}
func (e *InputCollectorCriblLakeLogLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		fallthrough
	case "silly":
		*e = InputCollectorCriblLakeLogLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectorCriblLakeLogLevel: %v", v)
	}
}

// InputCollectorCriblLakeMode - Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.
type InputCollectorCriblLakeMode string

const (
	InputCollectorCriblLakeModeList    InputCollectorCriblLakeMode = "list"
	InputCollectorCriblLakeModePreview InputCollectorCriblLakeMode = "preview"
	InputCollectorCriblLakeModeRun     InputCollectorCriblLakeMode = "run"
)

func (e InputCollectorCriblLakeMode) ToPointer() *InputCollectorCriblLakeMode {
	return &e
}
func (e *InputCollectorCriblLakeMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "list":
		fallthrough
	case "preview":
		fallthrough
	case "run":
		*e = InputCollectorCriblLakeMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectorCriblLakeMode: %v", v)
	}
}

type InputCollectorCriblLakeTimeRange string

const (
	InputCollectorCriblLakeTimeRangeRelative InputCollectorCriblLakeTimeRange = "relative"
	InputCollectorCriblLakeTimeRangeAbsolute InputCollectorCriblLakeTimeRange = "absolute"
)

func (e InputCollectorCriblLakeTimeRange) ToPointer() *InputCollectorCriblLakeTimeRange {
	return &e
}
func (e *InputCollectorCriblLakeTimeRange) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "relative":
		fallthrough
	case "absolute":
		*e = InputCollectorCriblLakeTimeRange(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectorCriblLakeTimeRange: %v", v)
	}
}

// InputCollectorCriblLakeTimeWarning - Time warning configuration
type InputCollectorCriblLakeTimeWarning struct {
}

func (i InputCollectorCriblLakeTimeWarning) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorCriblLakeTimeWarning) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

// InputCollectorCriblLakeStateTracking - State tracking configuration
type InputCollectorCriblLakeStateTracking struct {
	StateUpdateExpression *string `json:"stateUpdateExpression,omitempty"`
	StateMergeExpression  *string `json:"stateMergeExpression,omitempty"`
	Enabled               *bool   `default:"false" json:"enabled"`
}

func (i InputCollectorCriblLakeStateTracking) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorCriblLakeStateTracking) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorCriblLakeStateTracking) GetStateUpdateExpression() *string {
	if o == nil {
		return nil
	}
	return o.StateUpdateExpression
}

func (o *InputCollectorCriblLakeStateTracking) GetStateMergeExpression() *string {
	if o == nil {
		return nil
	}
	return o.StateMergeExpression
}

func (o *InputCollectorCriblLakeStateTracking) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

type InputCollectorCriblLakeRunSettings struct {
	// Reschedule tasks that failed with non-fatal errors
	RescheduleDroppedTasks *bool `default:"true" json:"rescheduleDroppedTasks"`
	// Maximum number of times a task can be rescheduled
	MaxTaskReschedule *float64 `default:"1" json:"maxTaskReschedule"`
	// Level at which to set task logging
	LogLevel *InputCollectorCriblLakeLogLevel `default:"info" json:"logLevel"`
	// Maximum time the job is allowed to run. Time unit defaults to seconds if not specified (examples: 30, 45s, 15m). Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.
	Mode          *InputCollectorCriblLakeMode      `default:"list" json:"mode"`
	TimeRangeType *InputCollectorCriblLakeTimeRange `default:"relative" json:"timeRangeType"`
	// Earliest time to collect data for the selected timezone
	Earliest *float64 `default:"0" json:"earliest"`
	// Latest time to collect data for the selected timezone
	Latest *float64 `default:"1" json:"latest"`
	// A filter for tokens in the provided collect path and/or the events being collected
	Expression *string `default:"true" json:"expression"`
	// Limits the bundle size for small tasks. For example, if your lower bundle size is 1MB, you can bundle up to five 200KB files into one task.
	MinTaskSize *string `default:"1MB" json:"minTaskSize"`
	// Limits the bundle size for files above the lower task bundle size. For example, if your upper bundle size is 10MB, you can bundle up to five 2MB files into one task. Files greater than this size will be assigned to individual tasks.
	MaxTaskSize *string `default:"10MB" json:"maxTaskSize"`
	// Time warning configuration
	TimeWarning *InputCollectorCriblLakeTimeWarning `json:"timeWarning,omitempty"`
	// State tracking configuration
	StateTracking *InputCollectorCriblLakeStateTracking `json:"stateTracking,omitempty"`
}

func (i InputCollectorCriblLakeRunSettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorCriblLakeRunSettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorCriblLakeRunSettings) GetRescheduleDroppedTasks() *bool {
	if o == nil {
		return nil
	}
	return o.RescheduleDroppedTasks
}

func (o *InputCollectorCriblLakeRunSettings) GetMaxTaskReschedule() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxTaskReschedule
}

func (o *InputCollectorCriblLakeRunSettings) GetLogLevel() *InputCollectorCriblLakeLogLevel {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *InputCollectorCriblLakeRunSettings) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputCollectorCriblLakeRunSettings) GetMode() *InputCollectorCriblLakeMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputCollectorCriblLakeRunSettings) GetTimeRangeType() *InputCollectorCriblLakeTimeRange {
	if o == nil {
		return nil
	}
	return o.TimeRangeType
}

func (o *InputCollectorCriblLakeRunSettings) GetEarliest() *float64 {
	if o == nil {
		return nil
	}
	return o.Earliest
}

func (o *InputCollectorCriblLakeRunSettings) GetLatest() *float64 {
	if o == nil {
		return nil
	}
	return o.Latest
}

func (o *InputCollectorCriblLakeRunSettings) GetExpression() *string {
	if o == nil {
		return nil
	}
	return o.Expression
}

func (o *InputCollectorCriblLakeRunSettings) GetMinTaskSize() *string {
	if o == nil {
		return nil
	}
	return o.MinTaskSize
}

func (o *InputCollectorCriblLakeRunSettings) GetMaxTaskSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxTaskSize
}

func (o *InputCollectorCriblLakeRunSettings) GetTimeWarning() *InputCollectorCriblLakeTimeWarning {
	if o == nil {
		return nil
	}
	return o.TimeWarning
}

func (o *InputCollectorCriblLakeRunSettings) GetStateTracking() *InputCollectorCriblLakeStateTracking {
	if o == nil {
		return nil
	}
	return o.StateTracking
}

// InputCollectorCriblLakeSchedule - Configuration for a scheduled job
type InputCollectorCriblLakeSchedule struct {
	// Enable to configure scheduling for this Collector
	Enabled *bool `json:"enabled,omitempty"`
	// A cron schedule on which to run this job
	CronSchedule *string `default:"*/5 * * * *" json:"cronSchedule"`
	// The maximum number of instances of this scheduled job that may be running at any time
	MaxConcurrentRuns *float64 `default:"1" json:"maxConcurrentRuns"`
	// Skippable jobs can be delayed, up to their next run time, if the system is hitting concurrency limits
	Skippable *bool `default:"true" json:"skippable"`
	// Resume missed scheduled runs
	ResumeMissed *bool                               `default:"false" json:"resumeMissed"`
	Run          *InputCollectorCriblLakeRunSettings `json:"run,omitempty"`
}

func (i InputCollectorCriblLakeSchedule) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorCriblLakeSchedule) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorCriblLakeSchedule) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *InputCollectorCriblLakeSchedule) GetCronSchedule() *string {
	if o == nil {
		return nil
	}
	return o.CronSchedule
}

func (o *InputCollectorCriblLakeSchedule) GetMaxConcurrentRuns() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentRuns
}

func (o *InputCollectorCriblLakeSchedule) GetSkippable() *bool {
	if o == nil {
		return nil
	}
	return o.Skippable
}

func (o *InputCollectorCriblLakeSchedule) GetResumeMissed() *bool {
	if o == nil {
		return nil
	}
	return o.ResumeMissed
}

func (o *InputCollectorCriblLakeSchedule) GetRun() *InputCollectorCriblLakeRunSettings {
	if o == nil {
		return nil
	}
	return o.Run
}

type InputCollectorCriblLakeTypeCollection2 string

const (
	InputCollectorCriblLakeTypeCollection2Collection InputCollectorCriblLakeTypeCollection2 = "collection"
)

func (e InputCollectorCriblLakeTypeCollection2) ToPointer() *InputCollectorCriblLakeTypeCollection2 {
	return &e
}
func (e *InputCollectorCriblLakeTypeCollection2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "collection":
		*e = InputCollectorCriblLakeTypeCollection2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectorCriblLakeTypeCollection2: %v", v)
	}
}

type InputCollectorCriblLakePreprocess struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (i InputCollectorCriblLakePreprocess) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorCriblLakePreprocess) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorCriblLakePreprocess) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCollectorCriblLakePreprocess) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *InputCollectorCriblLakePreprocess) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type InputCollectorCriblLakeMetadatum struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (i InputCollectorCriblLakeMetadatum) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorCriblLakeMetadatum) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorCriblLakeMetadatum) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputCollectorCriblLakeMetadatum) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCollectorCriblLakeInput struct {
	Type *InputCollectorCriblLakeTypeCollection2 `default:"collection" json:"type"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
	SendToRoutes *bool                              `default:"true" json:"sendToRoutes"`
	Preprocess   *InputCollectorCriblLakePreprocess `json:"preprocess,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `default:"0" json:"throttleRatePerSec"`
	// Fields to add to events from this input
	Metadata []InputCollectorCriblLakeMetadatum `json:"metadata,omitempty"`
	// Pipeline to process results
	Pipeline *string `json:"pipeline,omitempty"`
	// Destination to send results to
	Output *string `json:"output,omitempty"`
}

func (i InputCollectorCriblLakeInput) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorCriblLakeInput) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorCriblLakeInput) GetType() *InputCollectorCriblLakeTypeCollection2 {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputCollectorCriblLakeInput) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputCollectorCriblLakeInput) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputCollectorCriblLakeInput) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCollectorCriblLakeInput) GetPreprocess() *InputCollectorCriblLakePreprocess {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputCollectorCriblLakeInput) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *InputCollectorCriblLakeInput) GetMetadata() []InputCollectorCriblLakeMetadatum {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCollectorCriblLakeInput) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCollectorCriblLakeInput) GetOutput() *string {
	if o == nil {
		return nil
	}
	return o.Output
}

type TypeCribllake string

const (
	TypeCribllakeCribllake TypeCribllake = "cribllake"
)

func (e TypeCribllake) ToPointer() *TypeCribllake {
	return &e
}
func (e *TypeCribllake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribllake":
		*e = TypeCribllake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCribllake: %v", v)
	}
}

type InputCollectorCriblLakeConf struct {
	// Lake dataset to collect data from
	Dataset *string `json:"dataset,omitempty"`
}

func (i InputCollectorCriblLakeConf) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorCriblLakeConf) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorCriblLakeConf) GetDataset() *string {
	if o == nil {
		return nil
	}
	return o.Dataset
}

type InputCollectorCriblLakeCollector struct {
	Type TypeCribllake                `json:"type"`
	Conf *InputCollectorCriblLakeConf `json:"conf,omitempty"`
}

func (i InputCollectorCriblLakeCollector) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorCriblLakeCollector) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type"}); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorCriblLakeCollector) GetType() TypeCribllake {
	if o == nil {
		return TypeCribllake("")
	}
	return o.Type
}

func (o *InputCollectorCriblLakeCollector) GetConf() *InputCollectorCriblLakeConf {
	if o == nil {
		return nil
	}
	return o.Conf
}

type InputCollectorCriblLake struct {
	ID                   *string                                 `json:"id,omitempty"`
	Type                 *InputCollectorCriblLakeTypeCollection1 `default:"collection" json:"type"`
	TTL                  *string                                 `default:"4h" json:"ttl"`
	IgnoreGroupJobsLimit *bool                                   `default:"false" json:"ignoreGroupJobsLimit"`
	RemoveFields         []string                                `json:"removeFields,omitempty"`
	ResumeOnBoot         *bool                                   `default:"true" json:"resumeOnBoot"`
	Environment          *string                                 `json:"environment,omitempty"`
	// Saved state for the collector
	SavedState *InputCollectorCriblLakeSavedState `json:"savedState,omitempty"`
	// Configuration for a scheduled job
	Schedule *InputCollectorCriblLakeSchedule `json:"schedule,omitempty"`
	// Tags for filtering and grouping
	Streamtags []string `json:"streamtags,omitempty"`
	// If enabled, tasks are created and run by the same Worker Node
	WorkerAffinity *bool                            `default:"false" json:"workerAffinity"`
	Input          *InputCollectorCriblLakeInput    `json:"input,omitempty"`
	Collector      InputCollectorCriblLakeCollector `json:"collector"`
}

func (i InputCollectorCriblLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollectorCriblLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"collector"}); err != nil {
		return err
	}
	return nil
}

func (o *InputCollectorCriblLake) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputCollectorCriblLake) GetType() *InputCollectorCriblLakeTypeCollection1 {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputCollectorCriblLake) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputCollectorCriblLake) GetIgnoreGroupJobsLimit() *bool {
	if o == nil {
		return nil
	}
	return o.IgnoreGroupJobsLimit
}

func (o *InputCollectorCriblLake) GetRemoveFields() []string {
	if o == nil {
		return nil
	}
	return o.RemoveFields
}

func (o *InputCollectorCriblLake) GetResumeOnBoot() *bool {
	if o == nil {
		return nil
	}
	return o.ResumeOnBoot
}

func (o *InputCollectorCriblLake) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCollectorCriblLake) GetSavedState() *InputCollectorCriblLakeSavedState {
	if o == nil {
		return nil
	}
	return o.SavedState
}

func (o *InputCollectorCriblLake) GetSchedule() *InputCollectorCriblLakeSchedule {
	if o == nil {
		return nil
	}
	return o.Schedule
}

func (o *InputCollectorCriblLake) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCollectorCriblLake) GetWorkerAffinity() *bool {
	if o == nil {
		return nil
	}
	return o.WorkerAffinity
}

func (o *InputCollectorCriblLake) GetInput() *InputCollectorCriblLakeInput {
	if o == nil {
		return nil
	}
	return o.Input
}

func (o *InputCollectorCriblLake) GetCollector() InputCollectorCriblLakeCollector {
	if o == nil {
		return InputCollectorCriblLakeCollector{}
	}
	return o.Collector
}
