// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package provider

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	tfTypes "github.com/criblio/terraform-provider-criblio/internal/provider/types"
	"github.com/criblio/terraform-provider-criblio/internal/sdk"
	"github.com/criblio/terraform-provider-criblio/internal/sdk/models/operations"
	"github.com/criblio/terraform-provider-criblio/internal/validators"
	"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator"
	"github.com/hashicorp/terraform-plugin-framework/path"
	"github.com/hashicorp/terraform-plugin-framework/resource"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringdefault"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-framework/types/basetypes"
)

// Ensure provider defined types fully satisfy framework interfaces.
var _ resource.Resource = &CriblLakeDatasetResource{}
var _ resource.ResourceWithImportState = &CriblLakeDatasetResource{}

func NewCriblLakeDatasetResource() resource.Resource {
	return &CriblLakeDatasetResource{}
}

// CriblLakeDatasetResource defines the resource implementation.
type CriblLakeDatasetResource struct {
	// Provider configured SDK client.
	client *sdk.CriblIo
}

// CriblLakeDatasetResourceModel describes the resource data model.
type CriblLakeDatasetResourceModel struct {
	AcceleratedFields     []types.String                   `tfsdk:"accelerated_fields"`
	BucketName            types.String                     `tfsdk:"bucket_name"`
	Description           types.String                     `tfsdk:"description"`
	Format                types.String                     `tfsdk:"format"`
	ID                    types.String                     `tfsdk:"id"`
	Items                 []tfTypes.CriblLakeDataset       `tfsdk:"items"`
	LakeID                types.String                     `tfsdk:"lake_id"`
	RetentionPeriodInDays types.Float64                    `tfsdk:"retention_period_in_days"`
	SearchConfig          *tfTypes.LakeDatasetSearchConfig `tfsdk:"search_config"`
}

func (r *CriblLakeDatasetResource) Metadata(ctx context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_cribl_lake_dataset"
}

func (r *CriblLakeDatasetResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
	resp.Schema = schema.Schema{
		MarkdownDescription: "CriblLakeDataset Resource",
		Attributes: map[string]schema.Attribute{
			"accelerated_fields": schema.ListAttribute{
				Computed:    true,
				Optional:    true,
				ElementType: types.StringType,
			},
			"bucket_name": schema.StringAttribute{
				Computed:    true,
				Optional:    true,
				Default:     stringdefault.StaticString(`lake-${workspaceName}-${organizationId}`),
				Description: `Default: "lake-${workspaceName}-${organizationId}"`,
			},
			"description": schema.StringAttribute{
				Computed: true,
				Optional: true,
			},
			"format": schema.StringAttribute{
				Computed:    true,
				Optional:    true,
				Description: `must be one of ["json", "ddss", "parquet"]`,
				Validators: []validator.String{
					stringvalidator.OneOf(
						"json",
						"ddss",
						"parquet",
					),
				},
			},
			"id": schema.StringAttribute{
				Required:    true,
				Description: `dataset id to update`,
			},
			"items": schema.ListNestedAttribute{
				Computed: true,
				NestedObject: schema.NestedAttributeObject{
					Attributes: map[string]schema.Attribute{
						"accelerated_fields": schema.ListAttribute{
							Computed:    true,
							ElementType: types.StringType,
						},
						"bucket_name": schema.StringAttribute{
							Computed:    true,
							Default:     stringdefault.StaticString(`lake-${workspaceName}-${organizationId}`),
							Description: `Default: "lake-${workspaceName}-${organizationId}"`,
						},
						"description": schema.StringAttribute{
							Computed: true,
						},
						"format": schema.StringAttribute{
							Computed:    true,
							Description: `must be one of ["json", "ddss", "parquet"]`,
							Validators: []validator.String{
								stringvalidator.OneOf(
									"json",
									"ddss",
									"parquet",
								),
							},
						},
						"id": schema.StringAttribute{
							Computed: true,
						},
						"retention_period_in_days": schema.Float64Attribute{
							Computed: true,
						},
						"search_config": schema.SingleNestedAttribute{
							Computed: true,
							Attributes: map[string]schema.Attribute{
								"datatypes": schema.ListAttribute{
									Computed:    true,
									ElementType: types.StringType,
								},
								"metadata": schema.SingleNestedAttribute{
									Computed: true,
									Attributes: map[string]schema.Attribute{
										"created": schema.StringAttribute{
											Computed:    true,
											Description: `Creation timestamp`,
											Validators: []validator.String{
												validators.IsRFC3339(),
											},
										},
										"enable_acceleration": schema.BoolAttribute{
											Computed:    true,
											Default:     booldefault.StaticBool(false),
											Description: `Whether acceleration is enabled for this dataset. Default: false`,
										},
										"modified": schema.StringAttribute{
											Computed:    true,
											Description: `Last modification timestamp`,
											Validators: []validator.String{
												validators.IsRFC3339(),
											},
										},
										"tags": schema.ListAttribute{
											Computed:    true,
											ElementType: types.StringType,
											Description: `Tags associated with the dataset`,
										},
									},
								},
							},
						},
					},
				},
			},
			"lake_id": schema.StringAttribute{
				Required:    true,
				Description: `lake id that contains the Datasets. must be "default"`,
				Validators: []validator.String{
					stringvalidator.OneOf("default"),
				},
			},
			"retention_period_in_days": schema.Float64Attribute{
				Computed: true,
				Optional: true,
			},
			"search_config": schema.SingleNestedAttribute{
				Computed: true,
				Optional: true,
				Attributes: map[string]schema.Attribute{
					"datatypes": schema.ListAttribute{
						Computed:    true,
						Optional:    true,
						ElementType: types.StringType,
					},
					"metadata": schema.SingleNestedAttribute{
						Computed: true,
						Optional: true,
						Attributes: map[string]schema.Attribute{
							"created": schema.StringAttribute{
								Computed:    true,
								Optional:    true,
								Description: `Creation timestamp`,
								Validators: []validator.String{
									validators.IsRFC3339(),
								},
							},
							"enable_acceleration": schema.BoolAttribute{
								Computed:    true,
								Optional:    true,
								Default:     booldefault.StaticBool(false),
								Description: `Whether acceleration is enabled for this dataset. Default: false`,
							},
							"modified": schema.StringAttribute{
								Computed:    true,
								Optional:    true,
								Description: `Last modification timestamp`,
								Validators: []validator.String{
									validators.IsRFC3339(),
								},
							},
							"tags": schema.ListAttribute{
								Computed:    true,
								Optional:    true,
								ElementType: types.StringType,
								Description: `Tags associated with the dataset`,
							},
						},
					},
				},
			},
		},
	}
}

func (r *CriblLakeDatasetResource) Configure(ctx context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {
	// Prevent panic if the provider has not been configured.
	if req.ProviderData == nil {
		return
	}

	client, ok := req.ProviderData.(*sdk.CriblIo)

	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected Resource Configure Type",
			fmt.Sprintf("Expected *sdk.CriblIo, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)

		return
	}

	r.client = client
}

func (r *CriblLakeDatasetResource) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {
	var data *CriblLakeDatasetResourceModel
	var plan types.Object

	resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(plan.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsCreateCriblLakeDatasetByLakeIDRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.Lake.CreateCriblLakeDatasetByLakeID(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}
	if !(res.Object != nil && res.Object.Items != nil && len(res.Object.Items) > 0) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromSharedCriblLakeDataset(ctx, &res.Object.Items[0])...)

	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(refreshPlan(ctx, plan, &data)...)

	if resp.Diagnostics.HasError() {
		return
	}
	request1, request1Diags := data.ToOperationsGetCriblLakeDatasetByLakeIDAndIDRequest(ctx)
	resp.Diagnostics.Append(request1Diags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res1, err := r.client.Lake.GetCriblLakeDatasetByLakeIDAndID(ctx, *request1)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res1 != nil && res1.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res1.RawResponse))
		}
		return
	}
	if res1 == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res1))
		return
	}
	if res1.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res1.StatusCode), debugResponse(res1.RawResponse))
		return
	}
	if !(res1.Object != nil) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res1.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromOperationsGetCriblLakeDatasetByLakeIDAndIDResponseBody(ctx, res1.Object)...)

	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(refreshPlan(ctx, plan, &data)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *CriblLakeDatasetResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {
	var data *CriblLakeDatasetResourceModel
	var item types.Object

	resp.Diagnostics.Append(req.State.Get(ctx, &item)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(item.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsGetCriblLakeDatasetByLakeIDAndIDRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.Lake.GetCriblLakeDatasetByLakeIDAndID(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode == 404 {
		resp.State.RemoveResource(ctx)
		return
	}
	if res.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}
	if !(res.Object != nil) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromOperationsGetCriblLakeDatasetByLakeIDAndIDResponseBody(ctx, res.Object)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *CriblLakeDatasetResource) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {
	var data *CriblLakeDatasetResourceModel
	var plan types.Object

	resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)
	if resp.Diagnostics.HasError() {
		return
	}

	merge(ctx, req, resp, &data)
	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsUpdateCriblLakeDatasetByLakeIDAndIDRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.Lake.UpdateCriblLakeDatasetByLakeIDAndID(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}
	if !(res.Object != nil && res.Object.Items != nil && len(res.Object.Items) > 0) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromSharedCriblLakeDataset(ctx, &res.Object.Items[0])...)

	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(refreshPlan(ctx, plan, &data)...)

	if resp.Diagnostics.HasError() {
		return
	}
	request1, request1Diags := data.ToOperationsGetCriblLakeDatasetByLakeIDAndIDRequest(ctx)
	resp.Diagnostics.Append(request1Diags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res1, err := r.client.Lake.GetCriblLakeDatasetByLakeIDAndID(ctx, *request1)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res1 != nil && res1.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res1.RawResponse))
		}
		return
	}
	if res1 == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res1))
		return
	}
	if res1.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res1.StatusCode), debugResponse(res1.RawResponse))
		return
	}
	if !(res1.Object != nil) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res1.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromOperationsGetCriblLakeDatasetByLakeIDAndIDResponseBody(ctx, res1.Object)...)

	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(refreshPlan(ctx, plan, &data)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *CriblLakeDatasetResource) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {
	var data *CriblLakeDatasetResourceModel
	var item types.Object

	resp.Diagnostics.Append(req.State.Get(ctx, &item)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(item.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsDeleteCriblLakeDatasetByLakeIDAndIDRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.Lake.DeleteCriblLakeDatasetByLakeIDAndID(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}

}

func (r *CriblLakeDatasetResource) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {
	dec := json.NewDecoder(bytes.NewReader([]byte(req.ID)))
	dec.DisallowUnknownFields()
	var data struct {
		ID     string                                            `json:"id"`
		LakeID operations.GetCriblLakeDatasetByLakeIDAndIDLakeID `json:"lake_id"`
	}

	if err := dec.Decode(&data); err != nil {
		resp.Diagnostics.AddError("Invalid ID", `The import ID is not valid. It is expected to be a JSON object string with the format: '{"id": "web-logs", "lake_id": "default"}': `+err.Error())
		return
	}

	if len(data.ID) == 0 {
		resp.Diagnostics.AddError("Missing required field", `The field id is required but was not found in the json encoded ID. It's expected to be a value alike '"web-logs"`)
		return
	}
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("id"), data.ID)...)
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("lake_id"), data.LakeID)...)
}
