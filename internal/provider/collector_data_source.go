// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package provider

import (
	"context"
	"fmt"
	tfTypes "github.com/criblio/terraform-provider-criblio/internal/provider/types"
	"github.com/criblio/terraform-provider-criblio/internal/sdk"
	"github.com/hashicorp/terraform-plugin-framework/datasource"
	"github.com/hashicorp/terraform-plugin-framework/datasource/schema"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-framework/types/basetypes"
)

// Ensure provider defined types fully satisfy framework interfaces.
var _ datasource.DataSource = &CollectorDataSource{}
var _ datasource.DataSourceWithConfigure = &CollectorDataSource{}

func NewCollectorDataSource() datasource.DataSource {
	return &CollectorDataSource{}
}

// CollectorDataSource is the data source implementation.
type CollectorDataSource struct {
	// Provider configured SDK client.
	client *sdk.CriblIo
}

// CollectorDataSourceModel describes the data model.
type CollectorDataSourceModel struct {
	Environment               types.String                       `tfsdk:"environment"`
	GroupID                   types.String                       `tfsdk:"group_id"`
	ID                        types.String                       `tfsdk:"id"`
	IgnoreGroupJobsLimit      types.Bool                         `tfsdk:"ignore_group_jobs_limit"`
	InputCollectorAzureBlob   *tfTypes.InputCollectorAzureBlob   `queryParam:"inline" tfsdk:"input_collector_azure_blob" tfPlanOnly:"true"`
	InputCollectorCriblLake   *tfTypes.InputCollectorCriblLake   `queryParam:"inline" tfsdk:"input_collector_cribl_lake" tfPlanOnly:"true"`
	InputCollectorDatabase    *tfTypes.InputCollectorDatabase    `queryParam:"inline" tfsdk:"input_collector_database" tfPlanOnly:"true"`
	InputCollectorGCS         *tfTypes.InputCollectorGCS         `queryParam:"inline" tfsdk:"input_collector_gcs" tfPlanOnly:"true"`
	InputCollectorHealthCheck *tfTypes.InputCollectorHealthCheck `queryParam:"inline" tfsdk:"input_collector_health_check" tfPlanOnly:"true"`
	InputCollectorRest        *tfTypes.InputCollectorRest        `queryParam:"inline" tfsdk:"input_collector_rest" tfPlanOnly:"true"`
	InputCollectorS3          *tfTypes.InputCollectorS3          `queryParam:"inline" tfsdk:"input_collector_s3" tfPlanOnly:"true"`
	InputCollectorScript      *tfTypes.InputCollectorScript      `queryParam:"inline" tfsdk:"input_collector_script" tfPlanOnly:"true"`
	InputCollectorSplunk      *tfTypes.InputCollectorSplunk      `queryParam:"inline" tfsdk:"input_collector_splunk" tfPlanOnly:"true"`
	ResumeOnBoot              types.Bool                         `tfsdk:"resume_on_boot"`
	TTL                       types.String                       `tfsdk:"ttl"`
	WorkerAffinity            types.Bool                         `tfsdk:"worker_affinity"`
}

// Metadata returns the data source type name.
func (r *CollectorDataSource) Metadata(ctx context.Context, req datasource.MetadataRequest, resp *datasource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_collector"
}

// Schema defines the schema for the data source.
func (r *CollectorDataSource) Schema(ctx context.Context, req datasource.SchemaRequest, resp *datasource.SchemaResponse) {
	resp.Schema = schema.Schema{
		MarkdownDescription: "Collector DataSource",

		Attributes: map[string]schema.Attribute{
			"environment": schema.StringAttribute{
				Computed: true,
			},
			"group_id": schema.StringAttribute{
				Required:    true,
				Description: `The consumer group to which this instance belongs. Defaults to 'default'.`,
			},
			"id": schema.StringAttribute{
				Required:    true,
				Description: `Unique ID to GET`,
			},
			"ignore_group_jobs_limit": schema.BoolAttribute{
				Computed: true,
			},
			"input_collector_azure_blob": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"collector": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"conf": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"auth_type": schema.StringAttribute{
										Computed: true,
									},
									"connection_string": schema.StringAttribute{
										Computed:    true,
										Description: `Azure storage account Connection String`,
									},
									"container_name": schema.StringAttribute{
										Computed:    true,
										Description: `Azure container to collect from`,
									},
									"extractors": schema.ListNestedAttribute{
										Computed: true,
										NestedObject: schema.NestedAttributeObject{
											Attributes: map[string]schema.Attribute{
												"expression": schema.StringAttribute{
													Computed:    true,
													Description: `JavaScript expression to compute the value from the path`,
												},
												"key": schema.StringAttribute{
													Computed:    true,
													Description: `Name of the extracted field`,
												},
												"pattern": schema.StringAttribute{
													Computed:    true,
													Description: `Regex pattern to match paths (alternative to key/expression)`,
												},
											},
										},
									},
									"max_batch_size": schema.Int64Attribute{
										Computed: true,
									},
									"path": schema.StringAttribute{
										Computed:    true,
										Description: `Directory where data will be collected`,
									},
									"recurse": schema.BoolAttribute{
										Computed: true,
									},
									"storage_account_name": schema.StringAttribute{
										Computed: true,
									},
								},
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"environment": schema.StringAttribute{
						Computed: true,
					},
					"id": schema.StringAttribute{
						Computed: true,
					},
					"ignore_group_jobs_limit": schema.BoolAttribute{
						Computed: true,
					},
					"input": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"breaker_rulesets": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
								Description: `A list of event-breaking rulesets that will be applied, in order, to the input data stream`,
							},
							"metadata": schema.ListNestedAttribute{
								Computed: true,
								NestedObject: schema.NestedAttributeObject{
									Attributes: map[string]schema.Attribute{
										"name": schema.StringAttribute{
											Computed: true,
										},
										"value": schema.StringAttribute{
											Computed:    true,
											Description: `JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)`,
										},
									},
								},
								Description: `Fields to add to events from this input`,
							},
							"output": schema.StringAttribute{
								Computed:    true,
								Description: `Destination to send results to`,
							},
							"pipeline": schema.StringAttribute{
								Computed:    true,
								Description: `Pipeline to process results`,
							},
							"preprocess": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"args": schema.ListAttribute{
										Computed:    true,
										ElementType: types.StringType,
										Description: `Arguments to be added to the custom command`,
									},
									"command": schema.StringAttribute{
										Computed:    true,
										Description: `Command to feed the data through (via stdin) and process its output (stdout)`,
									},
									"disabled": schema.BoolAttribute{
										Computed: true,
									},
								},
							},
							"send_to_routes": schema.BoolAttribute{
								Computed:    true,
								Description: `Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.`,
							},
							"stale_channel_flush_ms": schema.Float64Attribute{
								Computed:    true,
								Description: `How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines`,
							},
							"throttle_rate_per_sec": schema.StringAttribute{
								Computed:    true,
								Description: `Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.`,
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"remove_fields": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
					},
					"resume_on_boot": schema.BoolAttribute{
						Computed: true,
					},
					"saved_state": schema.SingleNestedAttribute{
						Computed:    true,
						Description: `Saved state for the collector`,
					},
					"schedule": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"cron_schedule": schema.StringAttribute{
								Computed:    true,
								Description: `A cron schedule on which to run this job`,
							},
							"enabled": schema.BoolAttribute{
								Computed:    true,
								Description: `Enable to configure scheduling for this Collector`,
							},
							"max_concurrent_runs": schema.Float64Attribute{
								Computed:    true,
								Description: `The maximum number of instances of this scheduled job that may be running at any time`,
							},
							"resume_missed": schema.BoolAttribute{
								Computed:    true,
								Description: `Resume missed scheduled runs`,
							},
							"run": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"earliest": schema.Float64Attribute{
										Computed:    true,
										Description: `Earliest time to collect data for the selected timezone`,
									},
									"expression": schema.StringAttribute{
										Computed:    true,
										Description: `A filter for tokens in the provided collect path and/or the events being collected`,
									},
									"job_timeout": schema.StringAttribute{
										Computed:    true,
										Description: `Maximum time the job is allowed to run. Time unit defaults to seconds if not specified (examples: 30, 45s, 15m). Enter 0 for unlimited time.`,
									},
									"latest": schema.Float64Attribute{
										Computed:    true,
										Description: `Latest time to collect data for the selected timezone`,
									},
									"log_level": schema.StringAttribute{
										Computed:    true,
										Description: `Level at which to set task logging`,
									},
									"max_task_reschedule": schema.Float64Attribute{
										Computed:    true,
										Description: `Maximum number of times a task can be rescheduled`,
									},
									"max_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for files above the lower task bundle size. For example, if your upper bundle size is 10MB, you can bundle up to five 2MB files into one task. Files greater than this size will be assigned to individual tasks.`,
									},
									"min_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for small tasks. For example, if your lower bundle size is 1MB, you can bundle up to five 200KB files into one task.`,
									},
									"mode": schema.StringAttribute{
										Computed:    true,
										Description: `Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.`,
									},
									"reschedule_dropped_tasks": schema.BoolAttribute{
										Computed:    true,
										Description: `Reschedule tasks that failed with non-fatal errors`,
									},
									"state_tracking": schema.SingleNestedAttribute{
										Computed: true,
										Attributes: map[string]schema.Attribute{
											"enabled": schema.BoolAttribute{
												Computed: true,
											},
											"state_merge_expression": schema.StringAttribute{
												Computed: true,
											},
											"state_update_expression": schema.StringAttribute{
												Computed: true,
											},
										},
										Description: `State tracking configuration`,
									},
									"time_range_type": schema.StringAttribute{
										Computed: true,
									},
									"time_warning": schema.SingleNestedAttribute{
										Computed:    true,
										Description: `Time warning configuration`,
									},
								},
							},
							"skippable": schema.BoolAttribute{
								Computed:    true,
								Description: `Skippable jobs can be delayed, up to their next run time, if the system is hitting concurrency limits`,
							},
						},
						Description: `Configuration for a scheduled job`,
					},
					"streamtags": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
						Description: `Tags for filtering and grouping`,
					},
					"ttl": schema.StringAttribute{
						Computed: true,
					},
					"worker_affinity": schema.BoolAttribute{
						Computed:    true,
						Description: `If enabled, tasks are created and run by the same Worker Node`,
					},
				},
			},
			"input_collector_cribl_lake": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"collector": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"conf": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"dataset": schema.StringAttribute{
										Computed:    true,
										Description: `Lake dataset to collect data from`,
									},
								},
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"environment": schema.StringAttribute{
						Computed: true,
					},
					"id": schema.StringAttribute{
						Computed: true,
					},
					"ignore_group_jobs_limit": schema.BoolAttribute{
						Computed: true,
					},
					"input": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"breaker_rulesets": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
								Description: `A list of event-breaking rulesets that will be applied, in order, to the input data stream`,
							},
							"metadata": schema.ListNestedAttribute{
								Computed: true,
								NestedObject: schema.NestedAttributeObject{
									Attributes: map[string]schema.Attribute{
										"name": schema.StringAttribute{
											Computed: true,
										},
										"value": schema.StringAttribute{
											Computed:    true,
											Description: `JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)`,
										},
									},
								},
								Description: `Fields to add to events from this input`,
							},
							"output": schema.StringAttribute{
								Computed:    true,
								Description: `Destination to send results to`,
							},
							"pipeline": schema.StringAttribute{
								Computed:    true,
								Description: `Pipeline to process results`,
							},
							"preprocess": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"args": schema.ListAttribute{
										Computed:    true,
										ElementType: types.StringType,
										Description: `Arguments to be added to the custom command`,
									},
									"command": schema.StringAttribute{
										Computed:    true,
										Description: `Command to feed the data through (via stdin) and process its output (stdout)`,
									},
									"disabled": schema.BoolAttribute{
										Computed: true,
									},
								},
							},
							"send_to_routes": schema.BoolAttribute{
								Computed:    true,
								Description: `Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.`,
							},
							"stale_channel_flush_ms": schema.Float64Attribute{
								Computed:    true,
								Description: `How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines`,
							},
							"throttle_rate_per_sec": schema.StringAttribute{
								Computed:    true,
								Description: `Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.`,
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"remove_fields": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
					},
					"resume_on_boot": schema.BoolAttribute{
						Computed: true,
					},
					"saved_state": schema.SingleNestedAttribute{
						Computed:    true,
						Description: `Saved state for the collector`,
					},
					"schedule": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"cron_schedule": schema.StringAttribute{
								Computed:    true,
								Description: `A cron schedule on which to run this job`,
							},
							"enabled": schema.BoolAttribute{
								Computed:    true,
								Description: `Enable to configure scheduling for this Collector`,
							},
							"max_concurrent_runs": schema.Float64Attribute{
								Computed:    true,
								Description: `The maximum number of instances of this scheduled job that may be running at any time`,
							},
							"resume_missed": schema.BoolAttribute{
								Computed:    true,
								Description: `Resume missed scheduled runs`,
							},
							"run": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"earliest": schema.Float64Attribute{
										Computed:    true,
										Description: `Earliest time to collect data for the selected timezone`,
									},
									"expression": schema.StringAttribute{
										Computed:    true,
										Description: `A filter for tokens in the provided collect path and/or the events being collected`,
									},
									"job_timeout": schema.StringAttribute{
										Computed:    true,
										Description: `Maximum time the job is allowed to run. Time unit defaults to seconds if not specified (examples: 30, 45s, 15m). Enter 0 for unlimited time.`,
									},
									"latest": schema.Float64Attribute{
										Computed:    true,
										Description: `Latest time to collect data for the selected timezone`,
									},
									"log_level": schema.StringAttribute{
										Computed:    true,
										Description: `Level at which to set task logging`,
									},
									"max_task_reschedule": schema.Float64Attribute{
										Computed:    true,
										Description: `Maximum number of times a task can be rescheduled`,
									},
									"max_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for files above the lower task bundle size. For example, if your upper bundle size is 10MB, you can bundle up to five 2MB files into one task. Files greater than this size will be assigned to individual tasks.`,
									},
									"min_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for small tasks. For example, if your lower bundle size is 1MB, you can bundle up to five 200KB files into one task.`,
									},
									"mode": schema.StringAttribute{
										Computed:    true,
										Description: `Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.`,
									},
									"reschedule_dropped_tasks": schema.BoolAttribute{
										Computed:    true,
										Description: `Reschedule tasks that failed with non-fatal errors`,
									},
									"state_tracking": schema.SingleNestedAttribute{
										Computed: true,
										Attributes: map[string]schema.Attribute{
											"enabled": schema.BoolAttribute{
												Computed: true,
											},
											"state_merge_expression": schema.StringAttribute{
												Computed: true,
											},
											"state_update_expression": schema.StringAttribute{
												Computed: true,
											},
										},
										Description: `State tracking configuration`,
									},
									"time_range_type": schema.StringAttribute{
										Computed: true,
									},
									"time_warning": schema.SingleNestedAttribute{
										Computed:    true,
										Description: `Time warning configuration`,
									},
								},
							},
							"skippable": schema.BoolAttribute{
								Computed:    true,
								Description: `Skippable jobs can be delayed, up to their next run time, if the system is hitting concurrency limits`,
							},
						},
						Description: `Configuration for a scheduled job`,
					},
					"streamtags": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
						Description: `Tags for filtering and grouping`,
					},
					"ttl": schema.StringAttribute{
						Computed: true,
					},
					"worker_affinity": schema.BoolAttribute{
						Computed:    true,
						Description: `If enabled, tasks are created and run by the same Worker Node`,
					},
				},
			},
			"input_collector_database": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"collector": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"conf": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"connection_id": schema.StringAttribute{
										Computed:    true,
										Description: `Select an existing Database Connection`,
									},
									"query": schema.StringAttribute{
										Computed:    true,
										Description: `Query string for selecting data from the database`,
									},
									"query_validation_enabled": schema.BoolAttribute{
										Computed: true,
									},
								},
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"environment": schema.StringAttribute{
						Computed: true,
					},
					"id": schema.StringAttribute{
						Computed: true,
					},
					"ignore_group_jobs_limit": schema.BoolAttribute{
						Computed: true,
					},
					"input": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"breaker_rulesets": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
								Description: `A list of event-breaking rulesets that will be applied, in order, to the input data stream`,
							},
							"metadata": schema.ListNestedAttribute{
								Computed: true,
								NestedObject: schema.NestedAttributeObject{
									Attributes: map[string]schema.Attribute{
										"name": schema.StringAttribute{
											Computed: true,
										},
										"value": schema.StringAttribute{
											Computed:    true,
											Description: `JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)`,
										},
									},
								},
								Description: `Fields to add to events from this input`,
							},
							"output": schema.StringAttribute{
								Computed:    true,
								Description: `Destination to send results to`,
							},
							"pipeline": schema.StringAttribute{
								Computed:    true,
								Description: `Pipeline to process results`,
							},
							"preprocess": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"args": schema.ListAttribute{
										Computed:    true,
										ElementType: types.StringType,
										Description: `Arguments to be added to the custom command`,
									},
									"command": schema.StringAttribute{
										Computed:    true,
										Description: `Command to feed the data through (via stdin) and process its output (stdout)`,
									},
									"disabled": schema.BoolAttribute{
										Computed: true,
									},
								},
							},
							"send_to_routes": schema.BoolAttribute{
								Computed:    true,
								Description: `Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.`,
							},
							"stale_channel_flush_ms": schema.Float64Attribute{
								Computed:    true,
								Description: `How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines`,
							},
							"throttle_rate_per_sec": schema.StringAttribute{
								Computed:    true,
								Description: `Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.`,
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"remove_fields": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
					},
					"resume_on_boot": schema.BoolAttribute{
						Computed: true,
					},
					"saved_state": schema.SingleNestedAttribute{
						Computed:    true,
						Description: `Saved state for the collector`,
					},
					"schedule": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"cron_schedule": schema.StringAttribute{
								Computed:    true,
								Description: `A cron schedule on which to run this job`,
							},
							"enabled": schema.BoolAttribute{
								Computed:    true,
								Description: `Enable to configure scheduling for this Collector`,
							},
							"max_concurrent_runs": schema.Float64Attribute{
								Computed:    true,
								Description: `The maximum number of instances of this scheduled job that may be running at any time`,
							},
							"resume_missed": schema.BoolAttribute{
								Computed:    true,
								Description: `Resume missed scheduled runs`,
							},
							"run": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"earliest": schema.Float64Attribute{
										Computed:    true,
										Description: `Earliest time to collect data for the selected timezone`,
									},
									"expression": schema.StringAttribute{
										Computed:    true,
										Description: `A filter for tokens in the provided collect path and/or the events being collected`,
									},
									"job_timeout": schema.StringAttribute{
										Computed:    true,
										Description: `Maximum time the job is allowed to run. Time unit defaults to seconds if not specified (examples: 30, 45s, 15m). Enter 0 for unlimited time.`,
									},
									"latest": schema.Float64Attribute{
										Computed:    true,
										Description: `Latest time to collect data for the selected timezone`,
									},
									"log_level": schema.StringAttribute{
										Computed:    true,
										Description: `Level at which to set task logging`,
									},
									"max_task_reschedule": schema.Float64Attribute{
										Computed:    true,
										Description: `Maximum number of times a task can be rescheduled`,
									},
									"max_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for files above the lower task bundle size. For example, if your upper bundle size is 10MB, you can bundle up to five 2MB files into one task. Files greater than this size will be assigned to individual tasks.`,
									},
									"min_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for small tasks. For example, if your lower bundle size is 1MB, you can bundle up to five 200KB files into one task.`,
									},
									"mode": schema.StringAttribute{
										Computed:    true,
										Description: `Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.`,
									},
									"reschedule_dropped_tasks": schema.BoolAttribute{
										Computed:    true,
										Description: `Reschedule tasks that failed with non-fatal errors`,
									},
									"state_tracking": schema.SingleNestedAttribute{
										Computed: true,
										Attributes: map[string]schema.Attribute{
											"enabled": schema.BoolAttribute{
												Computed: true,
											},
											"state_merge_expression": schema.StringAttribute{
												Computed: true,
											},
											"state_update_expression": schema.StringAttribute{
												Computed: true,
											},
										},
										Description: `State tracking configuration`,
									},
									"time_range_type": schema.StringAttribute{
										Computed: true,
									},
									"time_warning": schema.SingleNestedAttribute{
										Computed:    true,
										Description: `Time warning configuration`,
									},
								},
							},
							"skippable": schema.BoolAttribute{
								Computed:    true,
								Description: `Skippable jobs can be delayed, up to their next run time, if the system is hitting concurrency limits`,
							},
						},
						Description: `Configuration for a scheduled job`,
					},
					"streamtags": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
						Description: `Tags for filtering and grouping`,
					},
					"ttl": schema.StringAttribute{
						Computed: true,
					},
					"worker_affinity": schema.BoolAttribute{
						Computed:    true,
						Description: `If enabled, tasks are created and run by the same Worker Node`,
					},
				},
			},
			"input_collector_gcs": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"collector": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"conf": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"auth_type": schema.StringAttribute{
										Computed: true,
									},
									"bucket": schema.StringAttribute{
										Computed:    true,
										Description: `GCS Bucket from which to collect data`,
									},
									"extractors": schema.ListNestedAttribute{
										Computed: true,
										NestedObject: schema.NestedAttributeObject{
											Attributes: map[string]schema.Attribute{
												"expression": schema.StringAttribute{
													Computed:    true,
													Description: `JavaScript expression to compute the value from the path`,
												},
												"key": schema.StringAttribute{
													Computed:    true,
													Description: `Name of the extracted field`,
												},
												"pattern": schema.StringAttribute{
													Computed:    true,
													Description: `Regex pattern to match paths (alternative to key/expression)`,
												},
											},
										},
									},
									"max_batch_size": schema.Int64Attribute{
										Computed: true,
									},
									"path": schema.StringAttribute{
										Computed:    true,
										Description: `Directory where data will be collected`,
									},
									"recurse": schema.BoolAttribute{
										Computed: true,
									},
									"service_account_credentials": schema.StringAttribute{
										Computed: true,
									},
								},
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"environment": schema.StringAttribute{
						Computed: true,
					},
					"id": schema.StringAttribute{
						Computed: true,
					},
					"ignore_group_jobs_limit": schema.BoolAttribute{
						Computed: true,
					},
					"input": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"breaker_rulesets": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
								Description: `A list of event-breaking rulesets that will be applied, in order, to the input data stream`,
							},
							"metadata": schema.ListNestedAttribute{
								Computed: true,
								NestedObject: schema.NestedAttributeObject{
									Attributes: map[string]schema.Attribute{
										"name": schema.StringAttribute{
											Computed: true,
										},
										"value": schema.StringAttribute{
											Computed:    true,
											Description: `JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)`,
										},
									},
								},
								Description: `Fields to add to events from this input`,
							},
							"output": schema.StringAttribute{
								Computed:    true,
								Description: `Destination to send results to`,
							},
							"pipeline": schema.StringAttribute{
								Computed:    true,
								Description: `Pipeline to process results`,
							},
							"preprocess": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"args": schema.ListAttribute{
										Computed:    true,
										ElementType: types.StringType,
										Description: `Arguments to be added to the custom command`,
									},
									"command": schema.StringAttribute{
										Computed:    true,
										Description: `Command to feed the data through (via stdin) and process its output (stdout)`,
									},
									"disabled": schema.BoolAttribute{
										Computed: true,
									},
								},
							},
							"send_to_routes": schema.BoolAttribute{
								Computed:    true,
								Description: `Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.`,
							},
							"stale_channel_flush_ms": schema.Float64Attribute{
								Computed:    true,
								Description: `How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines`,
							},
							"throttle_rate_per_sec": schema.StringAttribute{
								Computed:    true,
								Description: `Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.`,
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"remove_fields": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
					},
					"resume_on_boot": schema.BoolAttribute{
						Computed: true,
					},
					"saved_state": schema.SingleNestedAttribute{
						Computed:    true,
						Description: `Saved state for the collector`,
					},
					"schedule": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"cron_schedule": schema.StringAttribute{
								Computed:    true,
								Description: `A cron schedule on which to run this job`,
							},
							"enabled": schema.BoolAttribute{
								Computed:    true,
								Description: `Enable to configure scheduling for this Collector`,
							},
							"max_concurrent_runs": schema.Float64Attribute{
								Computed:    true,
								Description: `The maximum number of instances of this scheduled job that may be running at any time`,
							},
							"resume_missed": schema.BoolAttribute{
								Computed:    true,
								Description: `Resume missed scheduled runs`,
							},
							"run": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"earliest": schema.Float64Attribute{
										Computed:    true,
										Description: `Earliest time to collect data for the selected timezone`,
									},
									"expression": schema.StringAttribute{
										Computed:    true,
										Description: `A filter for tokens in the provided collect path and/or the events being collected`,
									},
									"job_timeout": schema.StringAttribute{
										Computed:    true,
										Description: `Maximum time the job is allowed to run. Time unit defaults to seconds if not specified (examples: 30, 45s, 15m). Enter 0 for unlimited time.`,
									},
									"latest": schema.Float64Attribute{
										Computed:    true,
										Description: `Latest time to collect data for the selected timezone`,
									},
									"log_level": schema.StringAttribute{
										Computed:    true,
										Description: `Level at which to set task logging`,
									},
									"max_task_reschedule": schema.Float64Attribute{
										Computed:    true,
										Description: `Maximum number of times a task can be rescheduled`,
									},
									"max_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for files above the lower task bundle size. For example, if your upper bundle size is 10MB, you can bundle up to five 2MB files into one task. Files greater than this size will be assigned to individual tasks.`,
									},
									"min_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for small tasks. For example, if your lower bundle size is 1MB, you can bundle up to five 200KB files into one task.`,
									},
									"mode": schema.StringAttribute{
										Computed:    true,
										Description: `Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.`,
									},
									"reschedule_dropped_tasks": schema.BoolAttribute{
										Computed:    true,
										Description: `Reschedule tasks that failed with non-fatal errors`,
									},
									"state_tracking": schema.SingleNestedAttribute{
										Computed: true,
										Attributes: map[string]schema.Attribute{
											"enabled": schema.BoolAttribute{
												Computed: true,
											},
											"state_merge_expression": schema.StringAttribute{
												Computed: true,
											},
											"state_update_expression": schema.StringAttribute{
												Computed: true,
											},
										},
										Description: `State tracking configuration`,
									},
									"time_range_type": schema.StringAttribute{
										Computed: true,
									},
									"time_warning": schema.SingleNestedAttribute{
										Computed:    true,
										Description: `Time warning configuration`,
									},
								},
							},
							"skippable": schema.BoolAttribute{
								Computed:    true,
								Description: `Skippable jobs can be delayed, up to their next run time, if the system is hitting concurrency limits`,
							},
						},
						Description: `Configuration for a scheduled job`,
					},
					"streamtags": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
						Description: `Tags for filtering and grouping`,
					},
					"ttl": schema.StringAttribute{
						Computed: true,
					},
					"worker_affinity": schema.BoolAttribute{
						Computed:    true,
						Description: `If enabled, tasks are created and run by the same Worker Node`,
					},
				},
			},
			"input_collector_health_check": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"collector": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"conf": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"authentication": schema.StringAttribute{
										Computed: true,
									},
									"collect_method": schema.StringAttribute{
										Computed: true,
									},
									"collect_url": schema.StringAttribute{
										Computed:    true,
										Description: `URL to use for the Collect operation`,
									},
									"credentials_secret": schema.StringAttribute{
										Computed: true,
									},
									"password": schema.StringAttribute{
										Computed: true,
									},
									"reject_unauthorized": schema.BoolAttribute{
										Computed: true,
									},
									"timeout": schema.Int64Attribute{
										Computed: true,
									},
									"username": schema.StringAttribute{
										Computed: true,
									},
								},
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"environment": schema.StringAttribute{
						Computed: true,
					},
					"id": schema.StringAttribute{
						Computed: true,
					},
					"ignore_group_jobs_limit": schema.BoolAttribute{
						Computed: true,
					},
					"input": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"breaker_rulesets": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
								Description: `A list of event-breaking rulesets that will be applied, in order, to the input data stream`,
							},
							"metadata": schema.ListNestedAttribute{
								Computed: true,
								NestedObject: schema.NestedAttributeObject{
									Attributes: map[string]schema.Attribute{
										"name": schema.StringAttribute{
											Computed: true,
										},
										"value": schema.StringAttribute{
											Computed:    true,
											Description: `JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)`,
										},
									},
								},
								Description: `Fields to add to events from this input`,
							},
							"output": schema.StringAttribute{
								Computed:    true,
								Description: `Destination to send results to`,
							},
							"pipeline": schema.StringAttribute{
								Computed:    true,
								Description: `Pipeline to process results`,
							},
							"preprocess": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"args": schema.ListAttribute{
										Computed:    true,
										ElementType: types.StringType,
										Description: `Arguments to be added to the custom command`,
									},
									"command": schema.StringAttribute{
										Computed:    true,
										Description: `Command to feed the data through (via stdin) and process its output (stdout)`,
									},
									"disabled": schema.BoolAttribute{
										Computed: true,
									},
								},
							},
							"send_to_routes": schema.BoolAttribute{
								Computed:    true,
								Description: `Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.`,
							},
							"stale_channel_flush_ms": schema.Float64Attribute{
								Computed:    true,
								Description: `How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines`,
							},
							"throttle_rate_per_sec": schema.StringAttribute{
								Computed:    true,
								Description: `Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.`,
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"remove_fields": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
					},
					"resume_on_boot": schema.BoolAttribute{
						Computed: true,
					},
					"saved_state": schema.SingleNestedAttribute{
						Computed:    true,
						Description: `Saved state for the collector`,
					},
					"schedule": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"cron_schedule": schema.StringAttribute{
								Computed:    true,
								Description: `A cron schedule on which to run this job`,
							},
							"enabled": schema.BoolAttribute{
								Computed:    true,
								Description: `Enable to configure scheduling for this Collector`,
							},
							"max_concurrent_runs": schema.Float64Attribute{
								Computed:    true,
								Description: `The maximum number of instances of this scheduled job that may be running at any time`,
							},
							"resume_missed": schema.BoolAttribute{
								Computed:    true,
								Description: `Resume missed scheduled runs`,
							},
							"run": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"earliest": schema.Float64Attribute{
										Computed:    true,
										Description: `Earliest time to collect data for the selected timezone`,
									},
									"expression": schema.StringAttribute{
										Computed:    true,
										Description: `A filter for tokens in the provided collect path and/or the events being collected`,
									},
									"job_timeout": schema.StringAttribute{
										Computed:    true,
										Description: `Maximum time the job is allowed to run. Time unit defaults to seconds if not specified (examples: 30, 45s, 15m). Enter 0 for unlimited time.`,
									},
									"latest": schema.Float64Attribute{
										Computed:    true,
										Description: `Latest time to collect data for the selected timezone`,
									},
									"log_level": schema.StringAttribute{
										Computed:    true,
										Description: `Level at which to set task logging`,
									},
									"max_task_reschedule": schema.Float64Attribute{
										Computed:    true,
										Description: `Maximum number of times a task can be rescheduled`,
									},
									"max_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for files above the lower task bundle size. For example, if your upper bundle size is 10MB, you can bundle up to five 2MB files into one task. Files greater than this size will be assigned to individual tasks.`,
									},
									"min_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for small tasks. For example, if your lower bundle size is 1MB, you can bundle up to five 200KB files into one task.`,
									},
									"mode": schema.StringAttribute{
										Computed:    true,
										Description: `Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.`,
									},
									"reschedule_dropped_tasks": schema.BoolAttribute{
										Computed:    true,
										Description: `Reschedule tasks that failed with non-fatal errors`,
									},
									"state_tracking": schema.SingleNestedAttribute{
										Computed: true,
										Attributes: map[string]schema.Attribute{
											"enabled": schema.BoolAttribute{
												Computed: true,
											},
											"state_merge_expression": schema.StringAttribute{
												Computed: true,
											},
											"state_update_expression": schema.StringAttribute{
												Computed: true,
											},
										},
										Description: `State tracking configuration`,
									},
									"time_range_type": schema.StringAttribute{
										Computed: true,
									},
									"time_warning": schema.SingleNestedAttribute{
										Computed:    true,
										Description: `Time warning configuration`,
									},
								},
							},
							"skippable": schema.BoolAttribute{
								Computed:    true,
								Description: `Skippable jobs can be delayed, up to their next run time, if the system is hitting concurrency limits`,
							},
						},
						Description: `Configuration for a scheduled job`,
					},
					"streamtags": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
						Description: `Tags for filtering and grouping`,
					},
					"ttl": schema.StringAttribute{
						Computed: true,
					},
					"worker_affinity": schema.BoolAttribute{
						Computed:    true,
						Description: `If enabled, tasks are created and run by the same Worker Node`,
					},
				},
			},
			"input_collector_rest": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"collector": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"conf": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"auth_header_expr": schema.StringAttribute{
										Computed:    true,
										Description: `Expression for auth header value`,
									},
									"auth_header_key": schema.StringAttribute{
										Computed:    true,
										Description: `Header key for authentication`,
									},
									"auth_request_headers": schema.ListNestedAttribute{
										Computed: true,
										NestedObject: schema.NestedAttributeObject{
											Attributes: map[string]schema.Attribute{
												"name": schema.StringAttribute{
													Computed: true,
												},
												"value": schema.StringAttribute{
													Computed: true,
												},
											},
										},
									},
									"auth_request_params": schema.ListNestedAttribute{
										Computed: true,
										NestedObject: schema.NestedAttributeObject{
											Attributes: map[string]schema.Attribute{
												"name": schema.StringAttribute{
													Computed: true,
												},
												"value": schema.StringAttribute{
													Computed: true,
												},
											},
										},
									},
									"authentication": schema.StringAttribute{
										Computed: true,
									},
									"capture_headers": schema.BoolAttribute{
										Computed: true,
									},
									"client_secret_param_name": schema.StringAttribute{
										Computed: true,
									},
									"collect_method": schema.StringAttribute{
										Computed: true,
									},
									"collect_request_headers": schema.ListNestedAttribute{
										Computed: true,
										NestedObject: schema.NestedAttributeObject{
											Attributes: map[string]schema.Attribute{
												"name": schema.StringAttribute{
													Computed: true,
												},
												"value": schema.StringAttribute{
													Computed: true,
												},
											},
										},
									},
									"collect_request_params": schema.ListNestedAttribute{
										Computed: true,
										NestedObject: schema.NestedAttributeObject{
											Attributes: map[string]schema.Attribute{
												"name": schema.StringAttribute{
													Computed: true,
												},
												"value": schema.StringAttribute{
													Computed: true,
												},
											},
										},
									},
									"collect_url": schema.StringAttribute{
										Computed:    true,
										Description: `URL to use for the Collect operation`,
									},
									"credentials_secret": schema.StringAttribute{
										Computed: true,
									},
									"decode_url": schema.BoolAttribute{
										Computed: true,
									},
									"disable_time_filter": schema.BoolAttribute{
										Computed: true,
									},
									"discovery": schema.SingleNestedAttribute{
										Computed: true,
										Attributes: map[string]schema.Attribute{
											"discover_body": schema.StringAttribute{
												Computed: true,
											},
											"discover_data_field": schema.StringAttribute{
												Computed: true,
											},
											"discover_method": schema.StringAttribute{
												Computed:    true,
												Description: `protocol used for http discovery, required for 'http' type`,
											},
											"discover_request_headers": schema.ListNestedAttribute{
												Computed: true,
												NestedObject: schema.NestedAttributeObject{
													Attributes: map[string]schema.Attribute{
														"name": schema.StringAttribute{
															Computed: true,
														},
														"value": schema.StringAttribute{
															Computed: true,
														},
													},
												},
											},
											"discover_request_params": schema.ListNestedAttribute{
												Computed: true,
												NestedObject: schema.NestedAttributeObject{
													Attributes: map[string]schema.Attribute{},
												},
											},
											"discover_type": schema.StringAttribute{
												Computed: true,
											},
											"discover_url": schema.StringAttribute{
												Computed:    true,
												Description: `URL to hit for rest type collectors, required for 'http' discoverType`,
											},
											"enable_discover_code": schema.BoolAttribute{
												Computed: true,
											},
											"format_result_code": schema.StringAttribute{
												Computed: true,
											},
											"item_list": schema.ListAttribute{
												Computed:    true,
												ElementType: types.StringType,
												Description: `comma separated list of strings to return from discovery section required for 'list' discoverType`,
											},
											"manual_discover_result": schema.StringAttribute{
												Computed:    true,
												Description: `json payload to return manually, required for 'json' discoverType`,
											},
											"pagination": schema.SingleNestedAttribute{
												Computed: true,
												Attributes: map[string]schema.Attribute{
													"attribute": schema.ListAttribute{
														Computed:    true,
														ElementType: types.StringType,
													},
													"last_page_expr": schema.StringAttribute{
														Computed: true,
													},
													"limit": schema.Int64Attribute{
														Computed: true,
													},
													"limit_field": schema.StringAttribute{
														Computed: true,
													},
													"max_pages": schema.Int64Attribute{
														Computed: true,
													},
													"offset": schema.Int64Attribute{
														Computed: true,
													},
													"offset_field": schema.StringAttribute{
														Computed: true,
													},
													"page_field": schema.StringAttribute{
														Computed: true,
													},
													"size": schema.Int64Attribute{
														Computed: true,
													},
													"size_field": schema.StringAttribute{
														Computed: true,
													},
													"total_record_field": schema.StringAttribute{
														Computed: true,
													},
													"type": schema.StringAttribute{
														Computed: true,
													},
													"zero_indexed": schema.BoolAttribute{
														Computed: true,
													},
												},
											},
										},
									},
									"login_body": schema.StringAttribute{
										Computed:    true,
										Description: `Body content for login request`,
									},
									"login_url": schema.StringAttribute{
										Computed:    true,
										Description: `URL for authentication login`,
									},
									"pagination": schema.SingleNestedAttribute{
										Computed: true,
										Attributes: map[string]schema.Attribute{
											"attribute": schema.ListAttribute{
												Computed:    true,
												ElementType: types.StringType,
											},
											"last_page_expr": schema.StringAttribute{
												Computed: true,
											},
											"limit": schema.Int64Attribute{
												Computed: true,
											},
											"limit_field": schema.StringAttribute{
												Computed: true,
											},
											"max_pages": schema.Int64Attribute{
												Computed: true,
											},
											"offset": schema.Int64Attribute{
												Computed: true,
											},
											"offset_field": schema.StringAttribute{
												Computed: true,
											},
											"page_field": schema.StringAttribute{
												Computed: true,
											},
											"size": schema.Int64Attribute{
												Computed: true,
											},
											"size_field": schema.StringAttribute{
												Computed: true,
											},
											"total_record_field": schema.StringAttribute{
												Computed: true,
											},
											"type": schema.StringAttribute{
												Computed: true,
											},
											"zero_indexed": schema.BoolAttribute{
												Computed: true,
											},
										},
									},
									"password": schema.StringAttribute{
										Computed: true,
									},
									"reject_unauthorized": schema.BoolAttribute{
										Computed: true,
									},
									"retry_rules": schema.SingleNestedAttribute{
										Computed: true,
										Attributes: map[string]schema.Attribute{
											"codes": schema.ListAttribute{
												Computed:    true,
												ElementType: types.Int64Type,
											},
											"enable_header": schema.BoolAttribute{
												Computed: true,
											},
											"interval": schema.Int64Attribute{
												Computed: true,
											},
											"limit": schema.Int64Attribute{
												Computed: true,
											},
											"max_interval_ms": schema.Int64Attribute{
												Computed: true,
											},
											"multiplier": schema.Float64Attribute{
												Computed: true,
											},
											"retry_connect_reset": schema.BoolAttribute{
												Computed: true,
											},
											"retry_connect_timeout": schema.BoolAttribute{
												Computed: true,
											},
											"retry_header_name": schema.StringAttribute{
												Computed: true,
											},
											"type": schema.StringAttribute{
												Computed: true,
											},
										},
									},
									"safe_headers": schema.ListAttribute{
										Computed:    true,
										ElementType: types.StringType,
									},
									"scheduling": schema.SingleNestedAttribute{
										Computed: true,
										Attributes: map[string]schema.Attribute{
											"state_tracking": schema.SingleNestedAttribute{
												Computed: true,
											},
										},
									},
									"timeout": schema.Int64Attribute{
										Computed: true,
									},
									"token": schema.StringAttribute{
										Computed: true,
									},
									"token_resp_attribute": schema.StringAttribute{
										Computed:    true,
										Description: `Attribute name for token in response`,
									},
									"token_secret": schema.StringAttribute{
										Computed: true,
									},
									"use_round_robin_dns": schema.BoolAttribute{
										Computed: true,
									},
									"username": schema.StringAttribute{
										Computed: true,
									},
								},
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"environment": schema.StringAttribute{
						Computed: true,
					},
					"id": schema.StringAttribute{
						Computed: true,
					},
					"ignore_group_jobs_limit": schema.BoolAttribute{
						Computed: true,
					},
					"input": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"breaker_rulesets": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
								Description: `A list of event-breaking rulesets that will be applied, in order, to the input data stream`,
							},
							"metadata": schema.ListNestedAttribute{
								Computed: true,
								NestedObject: schema.NestedAttributeObject{
									Attributes: map[string]schema.Attribute{
										"name": schema.StringAttribute{
											Computed: true,
										},
										"value": schema.StringAttribute{
											Computed:    true,
											Description: `JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)`,
										},
									},
								},
								Description: `Fields to add to events from this input`,
							},
							"output": schema.StringAttribute{
								Computed:    true,
								Description: `Destination to send results to`,
							},
							"pipeline": schema.StringAttribute{
								Computed:    true,
								Description: `Pipeline to process results`,
							},
							"preprocess": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"args": schema.ListAttribute{
										Computed:    true,
										ElementType: types.StringType,
										Description: `Arguments to be added to the custom command`,
									},
									"command": schema.StringAttribute{
										Computed:    true,
										Description: `Command to feed the data through (via stdin) and process its output (stdout)`,
									},
									"disabled": schema.BoolAttribute{
										Computed: true,
									},
								},
							},
							"send_to_routes": schema.BoolAttribute{
								Computed:    true,
								Description: `Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.`,
							},
							"stale_channel_flush_ms": schema.Float64Attribute{
								Computed:    true,
								Description: `How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines`,
							},
							"throttle_rate_per_sec": schema.StringAttribute{
								Computed:    true,
								Description: `Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.`,
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"remove_fields": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
					},
					"resume_on_boot": schema.BoolAttribute{
						Computed: true,
					},
					"saved_state": schema.SingleNestedAttribute{
						Computed:    true,
						Description: `Saved state for the collector`,
					},
					"schedule": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"cron_schedule": schema.StringAttribute{
								Computed:    true,
								Description: `A cron schedule on which to run this job`,
							},
							"enabled": schema.BoolAttribute{
								Computed:    true,
								Description: `Enable to configure scheduling for this Collector`,
							},
							"max_concurrent_runs": schema.Float64Attribute{
								Computed:    true,
								Description: `The maximum number of instances of this scheduled job that may be running at any time`,
							},
							"resume_missed": schema.BoolAttribute{
								Computed:    true,
								Description: `Resume missed scheduled runs`,
							},
							"run": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"earliest": schema.Float64Attribute{
										Computed:    true,
										Description: `Earliest time to collect data for the selected timezone`,
									},
									"expression": schema.StringAttribute{
										Computed:    true,
										Description: `A filter for tokens in the provided collect path and/or the events being collected`,
									},
									"job_timeout": schema.StringAttribute{
										Computed:    true,
										Description: `Maximum time the job is allowed to run. Time unit defaults to seconds if not specified (examples: 30, 45s, 15m). Enter 0 for unlimited time.`,
									},
									"latest": schema.Float64Attribute{
										Computed:    true,
										Description: `Latest time to collect data for the selected timezone`,
									},
									"log_level": schema.StringAttribute{
										Computed:    true,
										Description: `Level at which to set task logging`,
									},
									"max_task_reschedule": schema.Float64Attribute{
										Computed:    true,
										Description: `Maximum number of times a task can be rescheduled`,
									},
									"max_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for files above the lower task bundle size. For example, if your upper bundle size is 10MB, you can bundle up to five 2MB files into one task. Files greater than this size will be assigned to individual tasks.`,
									},
									"min_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for small tasks. For example, if your lower bundle size is 1MB, you can bundle up to five 200KB files into one task.`,
									},
									"mode": schema.StringAttribute{
										Computed:    true,
										Description: `Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.`,
									},
									"reschedule_dropped_tasks": schema.BoolAttribute{
										Computed:    true,
										Description: `Reschedule tasks that failed with non-fatal errors`,
									},
									"state_tracking": schema.SingleNestedAttribute{
										Computed: true,
										Attributes: map[string]schema.Attribute{
											"enabled": schema.BoolAttribute{
												Computed: true,
											},
											"state_merge_expression": schema.StringAttribute{
												Computed: true,
											},
											"state_update_expression": schema.StringAttribute{
												Computed: true,
											},
										},
										Description: `State tracking configuration`,
									},
									"time_range_type": schema.StringAttribute{
										Computed: true,
									},
									"time_warning": schema.SingleNestedAttribute{
										Computed:    true,
										Description: `Time warning configuration`,
									},
								},
							},
							"skippable": schema.BoolAttribute{
								Computed:    true,
								Description: `Skippable jobs can be delayed, up to their next run time, if the system is hitting concurrency limits`,
							},
						},
						Description: `Configuration for a scheduled job`,
					},
					"streamtags": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
						Description: `Tags for filtering and grouping`,
					},
					"ttl": schema.StringAttribute{
						Computed: true,
					},
					"worker_affinity": schema.BoolAttribute{
						Computed:    true,
						Description: `If enabled, tasks are created and run by the same Worker Node`,
					},
				},
			},
			"input_collector_s3": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"collector": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"conf": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"aws_api_key": schema.StringAttribute{
										Computed: true,
									},
									"aws_authentication_method": schema.StringAttribute{
										Computed: true,
									},
									"aws_secret": schema.StringAttribute{
										Computed: true,
									},
									"aws_secret_key": schema.StringAttribute{
										Computed: true,
									},
									"bucket": schema.StringAttribute{
										Computed:    true,
										Description: `S3 Bucket from which to collect data`,
									},
									"extractors": schema.ListNestedAttribute{
										Computed: true,
										NestedObject: schema.NestedAttributeObject{
											Attributes: map[string]schema.Attribute{
												"expression": schema.StringAttribute{
													Computed:    true,
													Description: `JavaScript expression to compute the value from the path`,
												},
												"key": schema.StringAttribute{
													Computed:    true,
													Description: `Name of the extracted field`,
												},
												"pattern": schema.StringAttribute{
													Computed:    true,
													Description: `Regex pattern to match paths (alternative to key/expression)`,
												},
											},
										},
									},
									"max_batch_size": schema.Int64Attribute{
										Computed: true,
									},
									"path": schema.StringAttribute{
										Computed:    true,
										Description: `Directory where data will be collected`,
									},
									"recurse": schema.BoolAttribute{
										Computed: true,
									},
									"region": schema.StringAttribute{
										Computed:    true,
										Description: `AWS region from which to retrieve data`,
									},
								},
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"environment": schema.StringAttribute{
						Computed: true,
					},
					"id": schema.StringAttribute{
						Computed: true,
					},
					"ignore_group_jobs_limit": schema.BoolAttribute{
						Computed: true,
					},
					"input": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"breaker_rulesets": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
								Description: `A list of event-breaking rulesets that will be applied, in order, to the input data stream`,
							},
							"metadata": schema.ListNestedAttribute{
								Computed: true,
								NestedObject: schema.NestedAttributeObject{
									Attributes: map[string]schema.Attribute{
										"name": schema.StringAttribute{
											Computed: true,
										},
										"value": schema.StringAttribute{
											Computed:    true,
											Description: `JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)`,
										},
									},
								},
								Description: `Fields to add to events from this input`,
							},
							"output": schema.StringAttribute{
								Computed:    true,
								Description: `Destination to send results to`,
							},
							"pipeline": schema.StringAttribute{
								Computed:    true,
								Description: `Pipeline to process results`,
							},
							"preprocess": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"args": schema.ListAttribute{
										Computed:    true,
										ElementType: types.StringType,
										Description: `Arguments to be added to the custom command`,
									},
									"command": schema.StringAttribute{
										Computed:    true,
										Description: `Command to feed the data through (via stdin) and process its output (stdout)`,
									},
									"disabled": schema.BoolAttribute{
										Computed: true,
									},
								},
							},
							"send_to_routes": schema.BoolAttribute{
								Computed:    true,
								Description: `Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.`,
							},
							"stale_channel_flush_ms": schema.Float64Attribute{
								Computed:    true,
								Description: `How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines`,
							},
							"throttle_rate_per_sec": schema.StringAttribute{
								Computed:    true,
								Description: `Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.`,
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"remove_fields": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
					},
					"resume_on_boot": schema.BoolAttribute{
						Computed: true,
					},
					"saved_state": schema.SingleNestedAttribute{
						Computed:    true,
						Description: `Saved state for the collector`,
					},
					"schedule": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"cron_schedule": schema.StringAttribute{
								Computed:    true,
								Description: `A cron schedule on which to run this job`,
							},
							"enabled": schema.BoolAttribute{
								Computed:    true,
								Description: `Enable to configure scheduling for this Collector`,
							},
							"max_concurrent_runs": schema.Float64Attribute{
								Computed:    true,
								Description: `The maximum number of instances of this scheduled job that may be running at any time`,
							},
							"resume_missed": schema.BoolAttribute{
								Computed:    true,
								Description: `Resume missed scheduled runs`,
							},
							"run": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"earliest": schema.Float64Attribute{
										Computed:    true,
										Description: `Earliest time to collect data for the selected timezone`,
									},
									"expression": schema.StringAttribute{
										Computed:    true,
										Description: `A filter for tokens in the provided collect path and/or the events being collected`,
									},
									"job_timeout": schema.StringAttribute{
										Computed:    true,
										Description: `Maximum time the job is allowed to run. Time unit defaults to seconds if not specified (examples: 30, 45s, 15m). Enter 0 for unlimited time.`,
									},
									"latest": schema.Float64Attribute{
										Computed:    true,
										Description: `Latest time to collect data for the selected timezone`,
									},
									"log_level": schema.StringAttribute{
										Computed:    true,
										Description: `Level at which to set task logging`,
									},
									"max_task_reschedule": schema.Float64Attribute{
										Computed:    true,
										Description: `Maximum number of times a task can be rescheduled`,
									},
									"max_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for files above the lower task bundle size. For example, if your upper bundle size is 10MB, you can bundle up to five 2MB files into one task. Files greater than this size will be assigned to individual tasks.`,
									},
									"min_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for small tasks. For example, if your lower bundle size is 1MB, you can bundle up to five 200KB files into one task.`,
									},
									"mode": schema.StringAttribute{
										Computed:    true,
										Description: `Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.`,
									},
									"reschedule_dropped_tasks": schema.BoolAttribute{
										Computed:    true,
										Description: `Reschedule tasks that failed with non-fatal errors`,
									},
									"state_tracking": schema.SingleNestedAttribute{
										Computed: true,
										Attributes: map[string]schema.Attribute{
											"enabled": schema.BoolAttribute{
												Computed: true,
											},
											"state_merge_expression": schema.StringAttribute{
												Computed: true,
											},
											"state_update_expression": schema.StringAttribute{
												Computed: true,
											},
										},
										Description: `State tracking configuration`,
									},
									"time_range_type": schema.StringAttribute{
										Computed: true,
									},
									"time_warning": schema.SingleNestedAttribute{
										Computed:    true,
										Description: `Time warning configuration`,
									},
								},
							},
							"skippable": schema.BoolAttribute{
								Computed:    true,
								Description: `Skippable jobs can be delayed, up to their next run time, if the system is hitting concurrency limits`,
							},
						},
						Description: `Configuration for a scheduled job`,
					},
					"streamtags": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
						Description: `Tags for filtering and grouping`,
					},
					"ttl": schema.StringAttribute{
						Computed: true,
					},
					"worker_affinity": schema.BoolAttribute{
						Computed:    true,
						Description: `If enabled, tasks are created and run by the same Worker Node`,
					},
				},
			},
			"input_collector_script": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"collector": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"conf": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"collect_script": schema.StringAttribute{
										Computed: true,
									},
									"discover_script": schema.StringAttribute{
										Computed: true,
									},
									"shell": schema.StringAttribute{
										Computed: true,
									},
								},
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"environment": schema.StringAttribute{
						Computed: true,
					},
					"id": schema.StringAttribute{
						Computed: true,
					},
					"ignore_group_jobs_limit": schema.BoolAttribute{
						Computed: true,
					},
					"input": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"breaker_rulesets": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
								Description: `A list of event-breaking rulesets that will be applied, in order, to the input data stream`,
							},
							"metadata": schema.ListNestedAttribute{
								Computed: true,
								NestedObject: schema.NestedAttributeObject{
									Attributes: map[string]schema.Attribute{
										"name": schema.StringAttribute{
											Computed: true,
										},
										"value": schema.StringAttribute{
											Computed:    true,
											Description: `JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)`,
										},
									},
								},
								Description: `Fields to add to events from this input`,
							},
							"output": schema.StringAttribute{
								Computed:    true,
								Description: `Destination to send results to`,
							},
							"pipeline": schema.StringAttribute{
								Computed:    true,
								Description: `Pipeline to process results`,
							},
							"preprocess": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"args": schema.ListAttribute{
										Computed:    true,
										ElementType: types.StringType,
										Description: `Arguments to be added to the custom command`,
									},
									"command": schema.StringAttribute{
										Computed:    true,
										Description: `Command to feed the data through (via stdin) and process its output (stdout)`,
									},
									"disabled": schema.BoolAttribute{
										Computed: true,
									},
								},
							},
							"send_to_routes": schema.BoolAttribute{
								Computed:    true,
								Description: `Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.`,
							},
							"stale_channel_flush_ms": schema.Float64Attribute{
								Computed:    true,
								Description: `How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines`,
							},
							"throttle_rate_per_sec": schema.StringAttribute{
								Computed:    true,
								Description: `Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.`,
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"remove_fields": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
					},
					"resume_on_boot": schema.BoolAttribute{
						Computed: true,
					},
					"saved_state": schema.SingleNestedAttribute{
						Computed:    true,
						Description: `Saved state for the collector`,
					},
					"schedule": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"cron_schedule": schema.StringAttribute{
								Computed:    true,
								Description: `A cron schedule on which to run this job`,
							},
							"enabled": schema.BoolAttribute{
								Computed:    true,
								Description: `Enable to configure scheduling for this Collector`,
							},
							"max_concurrent_runs": schema.Float64Attribute{
								Computed:    true,
								Description: `The maximum number of instances of this scheduled job that may be running at any time`,
							},
							"resume_missed": schema.BoolAttribute{
								Computed:    true,
								Description: `Resume missed scheduled runs`,
							},
							"run": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"earliest": schema.Float64Attribute{
										Computed:    true,
										Description: `Earliest time to collect data for the selected timezone`,
									},
									"expression": schema.StringAttribute{
										Computed:    true,
										Description: `A filter for tokens in the provided collect path and/or the events being collected`,
									},
									"job_timeout": schema.StringAttribute{
										Computed:    true,
										Description: `Maximum time the job is allowed to run. Time unit defaults to seconds if not specified (examples: 30, 45s, 15m). Enter 0 for unlimited time.`,
									},
									"latest": schema.Float64Attribute{
										Computed:    true,
										Description: `Latest time to collect data for the selected timezone`,
									},
									"log_level": schema.StringAttribute{
										Computed:    true,
										Description: `Level at which to set task logging`,
									},
									"max_task_reschedule": schema.Float64Attribute{
										Computed:    true,
										Description: `Maximum number of times a task can be rescheduled`,
									},
									"max_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for files above the lower task bundle size. For example, if your upper bundle size is 10MB, you can bundle up to five 2MB files into one task. Files greater than this size will be assigned to individual tasks.`,
									},
									"min_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for small tasks. For example, if your lower bundle size is 1MB, you can bundle up to five 200KB files into one task.`,
									},
									"mode": schema.StringAttribute{
										Computed:    true,
										Description: `Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.`,
									},
									"reschedule_dropped_tasks": schema.BoolAttribute{
										Computed:    true,
										Description: `Reschedule tasks that failed with non-fatal errors`,
									},
									"state_tracking": schema.SingleNestedAttribute{
										Computed: true,
										Attributes: map[string]schema.Attribute{
											"enabled": schema.BoolAttribute{
												Computed: true,
											},
											"state_merge_expression": schema.StringAttribute{
												Computed: true,
											},
											"state_update_expression": schema.StringAttribute{
												Computed: true,
											},
										},
										Description: `State tracking configuration`,
									},
									"time_range_type": schema.StringAttribute{
										Computed: true,
									},
									"time_warning": schema.SingleNestedAttribute{
										Computed:    true,
										Description: `Time warning configuration`,
									},
								},
							},
							"skippable": schema.BoolAttribute{
								Computed:    true,
								Description: `Skippable jobs can be delayed, up to their next run time, if the system is hitting concurrency limits`,
							},
						},
						Description: `Configuration for a scheduled job`,
					},
					"streamtags": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
						Description: `Tags for filtering and grouping`,
					},
					"ttl": schema.StringAttribute{
						Computed: true,
					},
					"worker_affinity": schema.BoolAttribute{
						Computed:    true,
						Description: `If enabled, tasks are created and run by the same Worker Node`,
					},
				},
			},
			"input_collector_splunk": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"collector": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"conf": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"authentication": schema.StringAttribute{
										Computed: true,
									},
									"credentials_secret": schema.StringAttribute{
										Computed: true,
									},
									"disable_time_filter": schema.BoolAttribute{
										Computed: true,
									},
									"earliest": schema.StringAttribute{
										Computed:    true,
										Description: `Earliest time boundary for the search`,
									},
									"endpoint": schema.StringAttribute{
										Computed:    true,
										Description: `REST API endpoint used to create a search`,
									},
									"handle_escaped_chars": schema.BoolAttribute{
										Computed: true,
									},
									"latest": schema.StringAttribute{
										Computed:    true,
										Description: `Latest time boundary for the search`,
									},
									"output_mode": schema.StringAttribute{
										Computed: true,
									},
									"password": schema.StringAttribute{
										Computed: true,
									},
									"reject_unauthorized": schema.BoolAttribute{
										Computed: true,
									},
									"search": schema.StringAttribute{
										Computed:    true,
										Description: `Splunk search query`,
									},
									"search_head": schema.StringAttribute{
										Computed:    true,
										Description: `Search head base URL`,
									},
									"timeout": schema.Int64Attribute{
										Computed: true,
									},
									"token": schema.StringAttribute{
										Computed: true,
									},
									"token_secret": schema.StringAttribute{
										Computed: true,
									},
									"use_round_robin_dns": schema.BoolAttribute{
										Computed: true,
									},
									"username": schema.StringAttribute{
										Computed: true,
									},
								},
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"environment": schema.StringAttribute{
						Computed: true,
					},
					"id": schema.StringAttribute{
						Computed: true,
					},
					"ignore_group_jobs_limit": schema.BoolAttribute{
						Computed: true,
					},
					"input": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"breaker_rulesets": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
								Description: `A list of event-breaking rulesets that will be applied, in order, to the input data stream`,
							},
							"metadata": schema.ListNestedAttribute{
								Computed: true,
								NestedObject: schema.NestedAttributeObject{
									Attributes: map[string]schema.Attribute{
										"name": schema.StringAttribute{
											Computed: true,
										},
										"value": schema.StringAttribute{
											Computed:    true,
											Description: `JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)`,
										},
									},
								},
								Description: `Fields to add to events from this input`,
							},
							"output": schema.StringAttribute{
								Computed:    true,
								Description: `Destination to send results to`,
							},
							"pipeline": schema.StringAttribute{
								Computed:    true,
								Description: `Pipeline to process results`,
							},
							"preprocess": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"args": schema.ListAttribute{
										Computed:    true,
										ElementType: types.StringType,
										Description: `Arguments to be added to the custom command`,
									},
									"command": schema.StringAttribute{
										Computed:    true,
										Description: `Command to feed the data through (via stdin) and process its output (stdout)`,
									},
									"disabled": schema.BoolAttribute{
										Computed: true,
									},
								},
							},
							"send_to_routes": schema.BoolAttribute{
								Computed:    true,
								Description: `Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.`,
							},
							"stale_channel_flush_ms": schema.Float64Attribute{
								Computed:    true,
								Description: `How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines`,
							},
							"throttle_rate_per_sec": schema.StringAttribute{
								Computed:    true,
								Description: `Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.`,
							},
							"type": schema.StringAttribute{
								Computed: true,
							},
						},
					},
					"remove_fields": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
					},
					"resume_on_boot": schema.BoolAttribute{
						Computed: true,
					},
					"saved_state": schema.SingleNestedAttribute{
						Computed:    true,
						Description: `Saved state for the collector`,
					},
					"schedule": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"cron_schedule": schema.StringAttribute{
								Computed:    true,
								Description: `A cron schedule on which to run this job`,
							},
							"enabled": schema.BoolAttribute{
								Computed:    true,
								Description: `Enable to configure scheduling for this Collector`,
							},
							"max_concurrent_runs": schema.Float64Attribute{
								Computed:    true,
								Description: `The maximum number of instances of this scheduled job that may be running at any time`,
							},
							"resume_missed": schema.BoolAttribute{
								Computed:    true,
								Description: `Resume missed scheduled runs`,
							},
							"run": schema.SingleNestedAttribute{
								Computed: true,
								Attributes: map[string]schema.Attribute{
									"earliest": schema.Float64Attribute{
										Computed:    true,
										Description: `Earliest time to collect data for the selected timezone`,
									},
									"expression": schema.StringAttribute{
										Computed:    true,
										Description: `A filter for tokens in the provided collect path and/or the events being collected`,
									},
									"job_timeout": schema.StringAttribute{
										Computed:    true,
										Description: `Maximum time the job is allowed to run. Time unit defaults to seconds if not specified (examples: 30, 45s, 15m). Enter 0 for unlimited time.`,
									},
									"latest": schema.Float64Attribute{
										Computed:    true,
										Description: `Latest time to collect data for the selected timezone`,
									},
									"log_level": schema.StringAttribute{
										Computed:    true,
										Description: `Level at which to set task logging`,
									},
									"max_task_reschedule": schema.Float64Attribute{
										Computed:    true,
										Description: `Maximum number of times a task can be rescheduled`,
									},
									"max_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for files above the lower task bundle size. For example, if your upper bundle size is 10MB, you can bundle up to five 2MB files into one task. Files greater than this size will be assigned to individual tasks.`,
									},
									"min_task_size": schema.StringAttribute{
										Computed:    true,
										Description: `Limits the bundle size for small tasks. For example, if your lower bundle size is 1MB, you can bundle up to five 200KB files into one task.`,
									},
									"mode": schema.StringAttribute{
										Computed:    true,
										Description: `Job run mode. Preview will either return up to N matching results, or will run until capture time T is reached. Discovery will gather the list of files to turn into streaming tasks, without running the data collection job. Full Run will run the collection job.`,
									},
									"reschedule_dropped_tasks": schema.BoolAttribute{
										Computed:    true,
										Description: `Reschedule tasks that failed with non-fatal errors`,
									},
									"state_tracking": schema.SingleNestedAttribute{
										Computed: true,
										Attributes: map[string]schema.Attribute{
											"enabled": schema.BoolAttribute{
												Computed: true,
											},
											"state_merge_expression": schema.StringAttribute{
												Computed: true,
											},
											"state_update_expression": schema.StringAttribute{
												Computed: true,
											},
										},
										Description: `State tracking configuration`,
									},
									"time_range_type": schema.StringAttribute{
										Computed: true,
									},
									"time_warning": schema.SingleNestedAttribute{
										Computed:    true,
										Description: `Time warning configuration`,
									},
								},
							},
							"skippable": schema.BoolAttribute{
								Computed:    true,
								Description: `Skippable jobs can be delayed, up to their next run time, if the system is hitting concurrency limits`,
							},
						},
						Description: `Configuration for a scheduled job`,
					},
					"streamtags": schema.ListAttribute{
						Computed:    true,
						ElementType: types.StringType,
						Description: `Tags for filtering and grouping`,
					},
					"ttl": schema.StringAttribute{
						Computed: true,
					},
					"worker_affinity": schema.BoolAttribute{
						Computed:    true,
						Description: `If enabled, tasks are created and run by the same Worker Node`,
					},
				},
			},
			"resume_on_boot": schema.BoolAttribute{
				Computed: true,
			},
			"ttl": schema.StringAttribute{
				Computed: true,
			},
			"worker_affinity": schema.BoolAttribute{
				Computed:    true,
				Description: `If enabled, tasks are created and run by the same Worker Node`,
			},
		},
	}
}

func (r *CollectorDataSource) Configure(ctx context.Context, req datasource.ConfigureRequest, resp *datasource.ConfigureResponse) {
	// Prevent panic if the provider has not been configured.
	if req.ProviderData == nil {
		return
	}

	client, ok := req.ProviderData.(*sdk.CriblIo)

	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected DataSource Configure Type",
			fmt.Sprintf("Expected *sdk.CriblIo, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)

		return
	}

	r.client = client
}

func (r *CollectorDataSource) Read(ctx context.Context, req datasource.ReadRequest, resp *datasource.ReadResponse) {
	var data *CollectorDataSourceModel
	var item types.Object

	resp.Diagnostics.Append(req.Config.Get(ctx, &item)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(item.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsGetSavedJobByIDRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.SavedJobs.GetSavedJobByID(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}
	if !(res.Object != nil) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromOperationsGetSavedJobByIDResponseBody(ctx, res.Object)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}
