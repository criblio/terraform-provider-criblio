// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package provider

import (
	"context"
	"fmt"
	tfTypes "github.com/criblio/terraform-provider-criblio/internal/provider/types"
	"github.com/criblio/terraform-provider-criblio/internal/sdk"
	"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator"
	"github.com/hashicorp/terraform-plugin-framework/datasource"
	"github.com/hashicorp/terraform-plugin-framework/datasource/schema"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-framework/types/basetypes"
	"regexp"
)

// Ensure provider defined types fully satisfy framework interfaces.
var _ datasource.DataSource = &EventBreakerRulesetDataSource{}
var _ datasource.DataSourceWithConfigure = &EventBreakerRulesetDataSource{}

func NewEventBreakerRulesetDataSource() datasource.DataSource {
	return &EventBreakerRulesetDataSource{}
}

// EventBreakerRulesetDataSource is the data source implementation.
type EventBreakerRulesetDataSource struct {
	// Provider configured SDK client.
	client *sdk.CriblIo
}

// EventBreakerRulesetDataSourceModel describes the data model.
type EventBreakerRulesetDataSourceModel struct {
	Description  types.String                      `tfsdk:"description"`
	GroupID      types.String                      `tfsdk:"group_id"`
	ID           types.String                      `tfsdk:"id"`
	Lib          types.String                      `tfsdk:"lib"`
	MinRawLength types.Float64                     `tfsdk:"min_raw_length"`
	Rules        []tfTypes.EventBreakerRulesetRule `tfsdk:"rules"`
	Tags         types.String                      `tfsdk:"tags"`
}

// Metadata returns the data source type name.
func (r *EventBreakerRulesetDataSource) Metadata(ctx context.Context, req datasource.MetadataRequest, resp *datasource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_event_breaker_ruleset"
}

// Schema defines the schema for the data source.
func (r *EventBreakerRulesetDataSource) Schema(ctx context.Context, req datasource.SchemaRequest, resp *datasource.SchemaResponse) {
	resp.Schema = schema.Schema{
		MarkdownDescription: "EventBreakerRuleset DataSource",

		Attributes: map[string]schema.Attribute{
			"description": schema.StringAttribute{
				Computed: true,
			},
			"group_id": schema.StringAttribute{
				Required:    true,
				Description: `The consumer group to which this instance belongs. Defaults to 'Cribl'.`,
			},
			"id": schema.StringAttribute{
				Required:    true,
				Description: `Unique ID to GET`,
				Validators: []validator.String{
					stringvalidator.RegexMatches(regexp.MustCompile(`^[a-zA-Z0-9\-_ ]+$`), "must match pattern "+regexp.MustCompile(`^[a-zA-Z0-9\-_ ]+$`).String()),
				},
			},
			"lib": schema.StringAttribute{
				Computed: true,
			},
			"min_raw_length": schema.Float64Attribute{
				Computed:    true,
				Description: `The  minimum number of characters in _raw to determine which rule to use`,
			},
			"rules": schema.ListNestedAttribute{
				Computed: true,
				NestedObject: schema.NestedAttributeObject{
					Attributes: map[string]schema.Attribute{
						"condition": schema.StringAttribute{
							Computed:    true,
							Description: `JavaScript expression applied to the beginning of a file or object, to determine whether the rule applies to all contained events.`,
						},
						"delimiter": schema.StringAttribute{
							Computed:    true,
							Description: `Field delimiter used for CSV parsing when type is "csv".`,
						},
						"delimiter_regex": schema.StringAttribute{
							Computed:    true,
							Description: `Regex used to split header fields when type is "header".`,
						},
						"disabled": schema.BoolAttribute{
							Computed:    true,
							Description: `Disable this breaker rule (enabled by default)`,
						},
						"escape_char": schema.StringAttribute{
							Computed:    true,
							Description: `Escape character used for CSV parsing when type is "csv".`,
						},
						"event_breaker_regex": schema.StringAttribute{
							Computed:    true,
							Description: `The regex to match before attempting event breaker extraction. Use $ (end-of-string anchor) to prevent extraction.`,
						},
						"fields": schema.ListNestedAttribute{
							Computed: true,
							NestedObject: schema.NestedAttributeObject{
								Attributes: map[string]schema.Attribute{
									"name": schema.StringAttribute{
										Computed: true,
									},
									"value": schema.StringAttribute{
										Computed:    true,
										Description: `The JavaScript expression used to compute the field's value (can be constant)`,
									},
								},
							},
							Description: `Key-value pairs to be added to each event`,
						},
						"fields_line_regex": schema.StringAttribute{
							Computed:    true,
							Description: `Regex that identifies and captures the fields line when type is "header".`,
						},
						"header_line_regex": schema.StringAttribute{
							Computed:    true,
							Description: `Regex used to identify header lines when type is "header".`,
						},
						"max_event_bytes": schema.Float64Attribute{
							Computed:    true,
							Description: `The maximum number of bytes in an event before it is flushed to the pipelines`,
						},
						"name": schema.StringAttribute{
							Computed: true,
						},
						"parser_enabled": schema.BoolAttribute{
							Computed: true,
						},
						"quote_char": schema.StringAttribute{
							Computed:    true,
							Description: `Quote character used for CSV parsing when type is "csv".`,
						},
						"should_use_data_raw": schema.BoolAttribute{
							Computed:    true,
							Description: `Enable to set an internal field on events indicating that the field in the data called _raw should be used. This can be useful for post processors that want to use that field for event._raw, instead of replacing it with the actual raw event.`,
						},
						"timestamp": schema.SingleNestedAttribute{
							Computed: true,
							Attributes: map[string]schema.Attribute{
								"format": schema.StringAttribute{
									Computed: true,
								},
								"length": schema.Float64Attribute{
									Computed: true,
								},
								"type": schema.StringAttribute{
									Computed: true,
								},
							},
							Description: `Auto, manual format (strptime), or current time`,
						},
						"timestamp_anchor_regex": schema.StringAttribute{
							Computed:    true,
							Description: `The regex to match before attempting timestamp extraction. Use $ (end-of-string anchor) to prevent extraction.`,
						},
						"timestamp_earliest": schema.StringAttribute{
							Computed:    true,
							Description: `The earliest timestamp value allowed relative to now. Example: -42years. Parsed values prior to this date will be set to current time.`,
						},
						"timestamp_latest": schema.StringAttribute{
							Computed:    true,
							Description: `The latest timestamp value allowed relative to now. Example: +42days. Parsed values after this date will be set to current time.`,
						},
						"timestamp_timezone": schema.StringAttribute{
							Computed:    true,
							Description: `Timezone to assign to timestamps without timezone info`,
						},
						"type": schema.StringAttribute{
							Computed: true,
						},
					},
				},
				Description: `A list of rules that will be applied, in order, to the input data stream`,
			},
			"tags": schema.StringAttribute{
				Computed: true,
			},
		},
	}
}

func (r *EventBreakerRulesetDataSource) Configure(ctx context.Context, req datasource.ConfigureRequest, resp *datasource.ConfigureResponse) {
	// Prevent panic if the provider has not been configured.
	if req.ProviderData == nil {
		return
	}

	client, ok := req.ProviderData.(*sdk.CriblIo)

	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected DataSource Configure Type",
			fmt.Sprintf("Expected *sdk.CriblIo, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)

		return
	}

	r.client = client
}

func (r *EventBreakerRulesetDataSource) Read(ctx context.Context, req datasource.ReadRequest, resp *datasource.ReadResponse) {
	var data *EventBreakerRulesetDataSourceModel
	var item types.Object

	resp.Diagnostics.Append(req.Config.Get(ctx, &item)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(item.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsGetEventBreakerRulesetByIDRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.EventBreakerRules.GetEventBreakerRulesetByID(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}
	if !(res.Object != nil) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromOperationsGetEventBreakerRulesetByIDResponseBody(ctx, res.Object)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}
